{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9a: PCA for Face Recognition\n",
    "    \n",
    "Following the demo for this unit, we will explore further the use of PCA for feature dimension reduction for classification. We will use a 2-layer neural net on the PCA coefficients. We will practice optimizing the classificaiton parameters (the number of PCA components and the number of hidden nodes in the NN classifier). We will furthermore compare this approach with using convolutional neural net on raw images.\n",
    "\n",
    "Through the lab, you will learn to:\n",
    "\n",
    "* Perform PCA on the a face dataset to find the PC components\n",
    "* Evaluate the effect of using different nubmer of principle components for data representation and classification.\n",
    "* Optimize the number of PC coefficients and classifier parameters together to maximize classification accuracy.\n",
    "* Understand the impact of training data size on the feature and classification method selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the flw_people dataset. \n",
    "# Select only those people with at least 100 instances \n",
    "# Reduce the face image size by 0.4\n",
    "\n",
    "# TO DO\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=100, resize=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size     = 50 x 37 = 1850 pixels\n",
      "Number faces   = 1140\n",
      "Number classes = 5\n"
     ]
    }
   ],
   "source": [
    "# Save the face images in a datamatrix X and the labels and corresponding names in a datamatrix y and target_names\n",
    "# Furthermore, determine the number of samples and the image size \n",
    "# Determine the number of different faces (number of classes)\n",
    "\n",
    "# TO DO\n",
    "# Get images\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "npix = h*w\n",
    "\n",
    "# Data in 2D form\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# Labels of images \n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print(\"Image size     = {0:d} x {1:d} = {2:d} pixels\".format(h,w,npix))\n",
    "print(\"Number faces   = {0:d}\".format(n_samples))\n",
    "print(\"Number classes = {0:d}\".format(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot some sample images to make sure your data load is correct\n",
    "def plt_face(x):\n",
    "    h = 50\n",
    "    w = 37\n",
    "    plt.imshow(x.reshape((h, w)), cmap=plt.cm.gray)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "I = np.random.permutation(n_samples)\n",
    "plt.figure(figsize=(10,20))\n",
    "nplt = 4;\n",
    "for i in range(nplt):    \n",
    "    ind = I[i]\n",
    "    plt.subplot(1,nplt,i+1)\n",
    "    plt_face(X[ind])\n",
    "    plt.title(target_names[y[ind]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and test set with 50% data for training. \n",
    "# Use \"stratify\" option to make sure the training data and test data have same \n",
    "# proportion of images from different faces\n",
    "# print the number of samples in the training data\n",
    "\n",
    "# TO DO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfom PCA on the training data to derive the principle components (PCs) and the PCA coefficients \n",
    "# You can directly use the PCA class in PCA package or use SVD.\n",
    "# Remember that you need to remove the mean from the data first\n",
    "# Also you should rescale the PCs so that the PCA coefficients all have unit variance\n",
    "# Determine the total number of PCs\n",
    "from sklearn.decomposition import PCA\n",
    "# TO DO \n",
    "npc = 100\n",
    "n_samples, _ = X_train.shape\n",
    "Xtr_mean = np.mean(X_train,0)\n",
    "Xtr = X_train - Xtr_mean[None,:]\n",
    "Xts_mean = np.mean(X_test,0)\n",
    "Xts = X_test - Xts_mean[None,:]\n",
    "# Utr,Str,Vtr = np.linalg.svd(Xtr, full_matrices=False)\n",
    "\n",
    "pca = PCA(n_components=npc, svd_solver='randomized', whiten=True).fit(Xtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First let us construct a 2-layer neural net classifier that uses npc= 100 PCA coefficients to classify the faces.  Set up your training and testing data to contain npc PCA coefficients using the previously determined principle components. You should directly use matrix multiplication (i.e. projecting original data to the first 100 principle components you found previously) to find the coefficients rather then using the pca.transform( ) method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "Xtr_pca = pca.transform(Xtr)\n",
    "Xts_pca = pca.transform(Xts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set up and compile a NN model with number of hidden nodes nnode=100 and a output layer, and then fit the model to the training data. Use 'relu' for the activation for the hidden layer and use 'softmax' for the output layer. Using `sparse_categorical_crossentropy` for the loss. Use `accuracy` as the metrics. You can choose to do a small number of epochs (=10) with batch size =100.  Determine the accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/eayn2k/anaconda3/envs/P3.7/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 10,605\n",
      "Trainable params: 10,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 570 samples, validate on 570 samples\n",
      "Epoch 1/1000\n",
      "570/570 [==============================] - 0s 348us/sample - loss: 1.8682 - acc: 0.2211 - val_loss: 1.7133 - val_acc: 0.2649\n",
      "Epoch 2/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 1.6952 - acc: 0.2754 - val_loss: 1.5956 - val_acc: 0.3140\n",
      "Epoch 3/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 1.5463 - acc: 0.3333 - val_loss: 1.4939 - val_acc: 0.3667\n",
      "Epoch 4/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 1.4191 - acc: 0.4123 - val_loss: 1.4074 - val_acc: 0.4228\n",
      "Epoch 5/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 1.3096 - acc: 0.4772 - val_loss: 1.3346 - val_acc: 0.4825\n",
      "Epoch 6/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 1.2149 - acc: 0.5316 - val_loss: 1.2725 - val_acc: 0.5158\n",
      "Epoch 7/1000\n",
      "570/570 [==============================] - 0s 25us/sample - loss: 1.1330 - acc: 0.5649 - val_loss: 1.2188 - val_acc: 0.5404\n",
      "Epoch 8/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 1.0585 - acc: 0.6140 - val_loss: 1.1714 - val_acc: 0.5754\n",
      "Epoch 9/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.9894 - acc: 0.6509 - val_loss: 1.1283 - val_acc: 0.6035\n",
      "Epoch 10/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.9272 - acc: 0.6895 - val_loss: 1.0883 - val_acc: 0.6228\n",
      "Epoch 11/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.8677 - acc: 0.7193 - val_loss: 1.0511 - val_acc: 0.6404\n",
      "Epoch 12/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.8112 - acc: 0.7439 - val_loss: 1.0161 - val_acc: 0.6579\n",
      "Epoch 13/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.7596 - acc: 0.7737 - val_loss: 0.9833 - val_acc: 0.6772\n",
      "Epoch 14/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.7103 - acc: 0.8105 - val_loss: 0.9529 - val_acc: 0.6895\n",
      "Epoch 15/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.6660 - acc: 0.8439 - val_loss: 0.9243 - val_acc: 0.7088\n",
      "Epoch 16/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.6248 - acc: 0.8579 - val_loss: 0.8975 - val_acc: 0.7175\n",
      "Epoch 17/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.5859 - acc: 0.8825 - val_loss: 0.8726 - val_acc: 0.7228\n",
      "Epoch 18/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.5501 - acc: 0.8860 - val_loss: 0.8493 - val_acc: 0.7298\n",
      "Epoch 19/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.5169 - acc: 0.8982 - val_loss: 0.8272 - val_acc: 0.7368\n",
      "Epoch 20/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.4857 - acc: 0.9175 - val_loss: 0.8066 - val_acc: 0.7474\n",
      "Epoch 21/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.4570 - acc: 0.9404 - val_loss: 0.7873 - val_acc: 0.7596\n",
      "Epoch 22/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.4301 - acc: 0.9421 - val_loss: 0.7689 - val_acc: 0.7596\n",
      "Epoch 23/1000\n",
      "570/570 [==============================] - 0s 24us/sample - loss: 0.4044 - acc: 0.9544 - val_loss: 0.7518 - val_acc: 0.7667\n",
      "Epoch 24/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.3812 - acc: 0.9596 - val_loss: 0.7359 - val_acc: 0.7702\n",
      "Epoch 25/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.3589 - acc: 0.9614 - val_loss: 0.7211 - val_acc: 0.7754\n",
      "Epoch 26/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.3383 - acc: 0.9649 - val_loss: 0.7071 - val_acc: 0.7807\n",
      "Epoch 27/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.3191 - acc: 0.9719 - val_loss: 0.6939 - val_acc: 0.7842\n",
      "Epoch 28/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.3013 - acc: 0.9772 - val_loss: 0.6817 - val_acc: 0.7895\n",
      "Epoch 29/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.2845 - acc: 0.9807 - val_loss: 0.6703 - val_acc: 0.7930\n",
      "Epoch 30/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.2686 - acc: 0.9825 - val_loss: 0.6595 - val_acc: 0.7965\n",
      "Epoch 31/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.2536 - acc: 0.9842 - val_loss: 0.6495 - val_acc: 0.8018\n",
      "Epoch 32/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.2405 - acc: 0.9860 - val_loss: 0.6402 - val_acc: 0.8000\n",
      "Epoch 33/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.2275 - acc: 0.9895 - val_loss: 0.6314 - val_acc: 0.8000\n",
      "Epoch 34/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.2157 - acc: 0.9895 - val_loss: 0.6233 - val_acc: 0.8000\n",
      "Epoch 35/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.2044 - acc: 0.9895 - val_loss: 0.6157 - val_acc: 0.8035\n",
      "Epoch 36/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.1938 - acc: 0.9947 - val_loss: 0.6086 - val_acc: 0.8088\n",
      "Epoch 37/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.1838 - acc: 0.9947 - val_loss: 0.6019 - val_acc: 0.8123\n",
      "Epoch 38/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.1750 - acc: 0.9982 - val_loss: 0.5956 - val_acc: 0.8140\n",
      "Epoch 39/1000\n",
      "570/570 [==============================] - 0s 25us/sample - loss: 0.1660 - acc: 0.9982 - val_loss: 0.5898 - val_acc: 0.8140\n",
      "Epoch 40/1000\n",
      "570/570 [==============================] - 0s 24us/sample - loss: 0.1581 - acc: 0.9982 - val_loss: 0.5843 - val_acc: 0.8158\n",
      "Epoch 41/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.1507 - acc: 0.9982 - val_loss: 0.5792 - val_acc: 0.8158\n",
      "Epoch 42/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.1435 - acc: 0.9982 - val_loss: 0.5746 - val_acc: 0.8158\n",
      "Epoch 43/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.1370 - acc: 1.0000 - val_loss: 0.5702 - val_acc: 0.8158\n",
      "Epoch 44/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.1306 - acc: 1.0000 - val_loss: 0.5661 - val_acc: 0.8211\n",
      "Epoch 45/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.1248 - acc: 1.0000 - val_loss: 0.5622 - val_acc: 0.8211\n",
      "Epoch 46/1000\n",
      "570/570 [==============================] - 0s 24us/sample - loss: 0.1193 - acc: 1.0000 - val_loss: 0.5585 - val_acc: 0.8246\n",
      "Epoch 47/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.1141 - acc: 1.0000 - val_loss: 0.5551 - val_acc: 0.8263\n",
      "Epoch 48/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.1093 - acc: 1.0000 - val_loss: 0.5519 - val_acc: 0.8263\n",
      "Epoch 49/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.1047 - acc: 1.0000 - val_loss: 0.5488 - val_acc: 0.8263\n",
      "Epoch 50/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 0.1003 - acc: 1.0000 - val_loss: 0.5460 - val_acc: 0.8281\n",
      "Epoch 51/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0963 - acc: 1.0000 - val_loss: 0.5433 - val_acc: 0.8298\n",
      "Epoch 52/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0924 - acc: 1.0000 - val_loss: 0.5409 - val_acc: 0.8298\n",
      "Epoch 53/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0888 - acc: 1.0000 - val_loss: 0.5385 - val_acc: 0.8316\n",
      "Epoch 54/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0853 - acc: 1.0000 - val_loss: 0.5363 - val_acc: 0.8333\n",
      "Epoch 55/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0821 - acc: 1.0000 - val_loss: 0.5342 - val_acc: 0.8351\n",
      "Epoch 56/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0791 - acc: 1.0000 - val_loss: 0.5321 - val_acc: 0.8368\n",
      "Epoch 57/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0762 - acc: 1.0000 - val_loss: 0.5302 - val_acc: 0.8368\n",
      "Epoch 58/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0734 - acc: 1.0000 - val_loss: 0.5284 - val_acc: 0.8368\n",
      "Epoch 59/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0709 - acc: 1.0000 - val_loss: 0.5267 - val_acc: 0.8368\n",
      "Epoch 60/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0683 - acc: 1.0000 - val_loss: 0.5251 - val_acc: 0.8386\n",
      "Epoch 61/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0660 - acc: 1.0000 - val_loss: 0.5237 - val_acc: 0.8386\n",
      "Epoch 62/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0637 - acc: 1.0000 - val_loss: 0.5223 - val_acc: 0.8404\n",
      "Epoch 63/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0616 - acc: 1.0000 - val_loss: 0.5210 - val_acc: 0.8421\n",
      "Epoch 64/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.0596 - acc: 1.0000 - val_loss: 0.5198 - val_acc: 0.8421\n",
      "Epoch 65/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0576 - acc: 1.0000 - val_loss: 0.5185 - val_acc: 0.8421\n",
      "Epoch 66/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0558 - acc: 1.0000 - val_loss: 0.5174 - val_acc: 0.8421\n",
      "Epoch 67/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0541 - acc: 1.0000 - val_loss: 0.5163 - val_acc: 0.8421\n",
      "Epoch 68/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0524 - acc: 1.0000 - val_loss: 0.5152 - val_acc: 0.8421\n",
      "Epoch 69/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0508 - acc: 1.0000 - val_loss: 0.5144 - val_acc: 0.8421\n",
      "Epoch 70/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0493 - acc: 1.0000 - val_loss: 0.5134 - val_acc: 0.8456\n",
      "Epoch 71/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0479 - acc: 1.0000 - val_loss: 0.5126 - val_acc: 0.8456\n",
      "Epoch 72/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0464 - acc: 1.0000 - val_loss: 0.5118 - val_acc: 0.8456\n",
      "Epoch 73/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0451 - acc: 1.0000 - val_loss: 0.5111 - val_acc: 0.8456\n",
      "Epoch 74/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0438 - acc: 1.0000 - val_loss: 0.5104 - val_acc: 0.8456\n",
      "Epoch 75/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0426 - acc: 1.0000 - val_loss: 0.5098 - val_acc: 0.8456\n",
      "Epoch 76/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0414 - acc: 1.0000 - val_loss: 0.5092 - val_acc: 0.8456\n",
      "Epoch 77/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0403 - acc: 1.0000 - val_loss: 0.5087 - val_acc: 0.8456\n",
      "Epoch 78/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0392 - acc: 1.0000 - val_loss: 0.5081 - val_acc: 0.8439\n",
      "Epoch 79/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0382 - acc: 1.0000 - val_loss: 0.5075 - val_acc: 0.8456\n",
      "Epoch 80/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0372 - acc: 1.0000 - val_loss: 0.5070 - val_acc: 0.8456\n",
      "Epoch 81/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0362 - acc: 1.0000 - val_loss: 0.5066 - val_acc: 0.8456\n",
      "Epoch 82/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0353 - acc: 1.0000 - val_loss: 0.5061 - val_acc: 0.8474\n",
      "Epoch 83/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0345 - acc: 1.0000 - val_loss: 0.5057 - val_acc: 0.8474\n",
      "Epoch 84/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0336 - acc: 1.0000 - val_loss: 0.5052 - val_acc: 0.8491\n",
      "Epoch 85/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0328 - acc: 1.0000 - val_loss: 0.5049 - val_acc: 0.8491\n",
      "Epoch 86/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 0.5046 - val_acc: 0.8491\n",
      "Epoch 87/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0312 - acc: 1.0000 - val_loss: 0.5043 - val_acc: 0.8491\n",
      "Epoch 88/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0305 - acc: 1.0000 - val_loss: 0.5039 - val_acc: 0.8491\n",
      "Epoch 89/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0298 - acc: 1.0000 - val_loss: 0.5036 - val_acc: 0.8491\n",
      "Epoch 90/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0291 - acc: 1.0000 - val_loss: 0.5032 - val_acc: 0.8509\n",
      "Epoch 91/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0284 - acc: 1.0000 - val_loss: 0.5029 - val_acc: 0.8509\n",
      "Epoch 92/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0278 - acc: 1.0000 - val_loss: 0.5026 - val_acc: 0.8509\n",
      "Epoch 93/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0272 - acc: 1.0000 - val_loss: 0.5024 - val_acc: 0.8491\n",
      "Epoch 94/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0266 - acc: 1.0000 - val_loss: 0.5022 - val_acc: 0.8491\n",
      "Epoch 95/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 0.5020 - val_acc: 0.8491\n",
      "Epoch 96/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 0.5018 - val_acc: 0.8509\n",
      "Epoch 97/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 0.5017 - val_acc: 0.8509\n",
      "Epoch 98/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 0.5016 - val_acc: 0.8526\n",
      "Epoch 99/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0239 - acc: 1.0000 - val_loss: 0.5015 - val_acc: 0.8526\n",
      "Epoch 100/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 0.5015 - val_acc: 0.8526\n",
      "Epoch 101/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.5014 - val_acc: 0.8526\n",
      "Epoch 102/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 0.5013 - val_acc: 0.8526\n",
      "Epoch 103/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 0.5012 - val_acc: 0.8526\n",
      "Epoch 104/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 0.5011 - val_acc: 0.8526\n",
      "Epoch 105/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.5010 - val_acc: 0.8526\n",
      "Epoch 106/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.5010 - val_acc: 0.8544\n",
      "Epoch 107/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.5010 - val_acc: 0.8544\n",
      "Epoch 108/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.5011 - val_acc: 0.8544\n",
      "Epoch 109/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.5011 - val_acc: 0.8561\n",
      "Epoch 110/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.5010 - val_acc: 0.8526\n",
      "Epoch 111/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.5010 - val_acc: 0.8544\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.5011 - val_acc: 0.8544\n",
      "Epoch 113/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.5011 - val_acc: 0.8561\n",
      "Epoch 114/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 0.5010 - val_acc: 0.8544\n",
      "Epoch 115/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.5011 - val_acc: 0.8544\n",
      "Epoch 116/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.5012 - val_acc: 0.8544\n",
      "Epoch 117/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.5012 - val_acc: 0.8544\n",
      "Epoch 118/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.5012 - val_acc: 0.8544\n",
      "Epoch 119/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.5013 - val_acc: 0.8544\n",
      "Epoch 120/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.5013 - val_acc: 0.8544\n",
      "Epoch 121/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.5015 - val_acc: 0.8544\n",
      "Epoch 122/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.5016 - val_acc: 0.8544\n",
      "Epoch 123/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.5017 - val_acc: 0.8561\n",
      "Epoch 124/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.5018 - val_acc: 0.8561\n",
      "Epoch 125/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.5019 - val_acc: 0.8561\n",
      "Epoch 126/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.5020 - val_acc: 0.8544\n",
      "Epoch 127/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.5020 - val_acc: 0.8544\n",
      "Epoch 128/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.5021 - val_acc: 0.8544\n",
      "Epoch 129/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.5023 - val_acc: 0.8544\n",
      "Epoch 130/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.5024 - val_acc: 0.8544\n",
      "Epoch 131/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.5025 - val_acc: 0.8544\n",
      "Epoch 132/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.5026 - val_acc: 0.8544\n",
      "Epoch 133/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.5027 - val_acc: 0.8561\n",
      "Epoch 134/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.5029 - val_acc: 0.8561\n",
      "Epoch 135/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.5030 - val_acc: 0.8561\n",
      "Epoch 136/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.5032 - val_acc: 0.8561\n",
      "Epoch 137/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.5033 - val_acc: 0.8544\n",
      "Epoch 138/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.5034 - val_acc: 0.8544\n",
      "Epoch 139/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.5036 - val_acc: 0.8544\n",
      "Epoch 140/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.5037 - val_acc: 0.8544\n",
      "Epoch 141/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.5038 - val_acc: 0.8544\n",
      "Epoch 142/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.5040 - val_acc: 0.8544\n",
      "Epoch 143/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.5041 - val_acc: 0.8544\n",
      "Epoch 144/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.5042 - val_acc: 0.8544\n",
      "Epoch 145/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.5044 - val_acc: 0.8544\n",
      "Epoch 146/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.5045 - val_acc: 0.8544\n",
      "Epoch 147/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.5047 - val_acc: 0.8544\n",
      "Epoch 148/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.5048 - val_acc: 0.8544\n",
      "Epoch 149/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.5050 - val_acc: 0.8544\n",
      "Epoch 150/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.5051 - val_acc: 0.8544\n",
      "Epoch 151/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.5053 - val_acc: 0.8544\n",
      "Epoch 152/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.5054 - val_acc: 0.8544\n",
      "Epoch 153/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.5055 - val_acc: 0.8544\n",
      "Epoch 154/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.5057 - val_acc: 0.8544\n",
      "Epoch 155/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.5058 - val_acc: 0.8544\n",
      "Epoch 156/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.5060 - val_acc: 0.8544\n",
      "Epoch 157/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.5062 - val_acc: 0.8544\n",
      "Epoch 158/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.5064 - val_acc: 0.8544\n",
      "Epoch 159/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.5065 - val_acc: 0.8544\n",
      "Epoch 160/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.5067 - val_acc: 0.8544\n",
      "Epoch 161/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.5069 - val_acc: 0.8544\n",
      "Epoch 162/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.5071 - val_acc: 0.8544\n",
      "Epoch 163/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.5073 - val_acc: 0.8544\n",
      "Epoch 164/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.5075 - val_acc: 0.8544\n",
      "Epoch 165/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.5077 - val_acc: 0.8544\n",
      "Epoch 166/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.5079 - val_acc: 0.8544\n",
      "Epoch 167/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.5081 - val_acc: 0.8544\n",
      "Epoch 168/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.5082 - val_acc: 0.8544\n",
      "Epoch 169/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5084 - val_acc: 0.8544\n",
      "Epoch 170/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5086 - val_acc: 0.8561\n",
      "Epoch 171/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5088 - val_acc: 0.8561\n",
      "Epoch 172/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.5090 - val_acc: 0.8544\n",
      "Epoch 173/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.5092 - val_acc: 0.8561\n",
      "Epoch 174/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.5094 - val_acc: 0.8561\n",
      "Epoch 175/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.5095 - val_acc: 0.8561\n",
      "Epoch 176/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.5097 - val_acc: 0.8561\n",
      "Epoch 177/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.5099 - val_acc: 0.8561\n",
      "Epoch 178/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5100 - val_acc: 0.8561\n",
      "Epoch 179/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5102 - val_acc: 0.8561\n",
      "Epoch 180/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.5104 - val_acc: 0.8561\n",
      "Epoch 181/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.5106 - val_acc: 0.8561\n",
      "Epoch 182/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5108 - val_acc: 0.8561\n",
      "Epoch 183/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5110 - val_acc: 0.8561\n",
      "Epoch 184/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.5111 - val_acc: 0.8561\n",
      "Epoch 185/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.5113 - val_acc: 0.8561\n",
      "Epoch 186/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.5115 - val_acc: 0.8579\n",
      "Epoch 187/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.5117 - val_acc: 0.8579\n",
      "Epoch 188/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5119 - val_acc: 0.8579\n",
      "Epoch 189/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.5121 - val_acc: 0.8579\n",
      "Epoch 190/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.5123 - val_acc: 0.8579\n",
      "Epoch 191/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5125 - val_acc: 0.8579\n",
      "Epoch 192/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5127 - val_acc: 0.8579\n",
      "Epoch 193/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5128 - val_acc: 0.8579\n",
      "Epoch 194/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.5130 - val_acc: 0.8579\n",
      "Epoch 195/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5132 - val_acc: 0.8579\n",
      "Epoch 196/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5134 - val_acc: 0.8579\n",
      "Epoch 197/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5136 - val_acc: 0.8579\n",
      "Epoch 198/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5138 - val_acc: 0.8579\n",
      "Epoch 199/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5140 - val_acc: 0.8579\n",
      "Epoch 200/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5142 - val_acc: 0.8579\n",
      "Epoch 201/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5144 - val_acc: 0.8579\n",
      "Epoch 202/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5146 - val_acc: 0.8579\n",
      "Epoch 203/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5148 - val_acc: 0.8579\n",
      "Epoch 204/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.5149 - val_acc: 0.8579\n",
      "Epoch 205/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.5151 - val_acc: 0.8579\n",
      "Epoch 206/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5153 - val_acc: 0.8579\n",
      "Epoch 207/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5155 - val_acc: 0.8579\n",
      "Epoch 208/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5157 - val_acc: 0.8579\n",
      "Epoch 209/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5159 - val_acc: 0.8579\n",
      "Epoch 210/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5161 - val_acc: 0.8579\n",
      "Epoch 211/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5164 - val_acc: 0.8579\n",
      "Epoch 212/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5165 - val_acc: 0.8579\n",
      "Epoch 213/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5167 - val_acc: 0.8579\n",
      "Epoch 214/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5169 - val_acc: 0.8579\n",
      "Epoch 215/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5171 - val_acc: 0.8579\n",
      "Epoch 216/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5173 - val_acc: 0.8579\n",
      "Epoch 217/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5175 - val_acc: 0.8579\n",
      "Epoch 218/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5177 - val_acc: 0.8579\n",
      "Epoch 219/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5179 - val_acc: 0.8579\n",
      "Epoch 220/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5180 - val_acc: 0.8579\n",
      "Epoch 221/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5182 - val_acc: 0.8579\n",
      "Epoch 222/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5184 - val_acc: 0.8579\n",
      "Epoch 223/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5186 - val_acc: 0.8579\n",
      "Epoch 224/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5188 - val_acc: 0.8579\n",
      "Epoch 225/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5190 - val_acc: 0.8579\n",
      "Epoch 226/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5192 - val_acc: 0.8596\n",
      "Epoch 227/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5194 - val_acc: 0.8596\n",
      "Epoch 228/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5196 - val_acc: 0.8596\n",
      "Epoch 229/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5198 - val_acc: 0.8596\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5200 - val_acc: 0.8596\n",
      "Epoch 231/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5202 - val_acc: 0.8596\n",
      "Epoch 232/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5205 - val_acc: 0.8596\n",
      "Epoch 233/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5207 - val_acc: 0.8596\n",
      "Epoch 234/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5209 - val_acc: 0.8596\n",
      "Epoch 235/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5211 - val_acc: 0.8596\n",
      "Epoch 236/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5213 - val_acc: 0.8596\n",
      "Epoch 237/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5214 - val_acc: 0.8596\n",
      "Epoch 238/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5217 - val_acc: 0.8596\n",
      "Epoch 239/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5219 - val_acc: 0.8596\n",
      "Epoch 240/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5221 - val_acc: 0.8614\n",
      "Epoch 241/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5223 - val_acc: 0.8614\n",
      "Epoch 242/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5224 - val_acc: 0.8614\n",
      "Epoch 243/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5226 - val_acc: 0.8614\n",
      "Epoch 244/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5228 - val_acc: 0.8614\n",
      "Epoch 245/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5230 - val_acc: 0.8614\n",
      "Epoch 246/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5232 - val_acc: 0.8614\n",
      "Epoch 247/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5234 - val_acc: 0.8614\n",
      "Epoch 248/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5236 - val_acc: 0.8614\n",
      "Epoch 249/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5237 - val_acc: 0.8614\n",
      "Epoch 250/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5239 - val_acc: 0.8614\n",
      "Epoch 251/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5241 - val_acc: 0.8614\n",
      "Epoch 252/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5243 - val_acc: 0.8614\n",
      "Epoch 253/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5245 - val_acc: 0.8614\n",
      "Epoch 254/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5247 - val_acc: 0.8614\n",
      "Epoch 255/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5249 - val_acc: 0.8614\n",
      "Epoch 256/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5251 - val_acc: 0.8614\n",
      "Epoch 257/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5253 - val_acc: 0.8614\n",
      "Epoch 258/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.5254 - val_acc: 0.8614\n",
      "Epoch 259/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.5256 - val_acc: 0.8614\n",
      "Epoch 260/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.5258 - val_acc: 0.8614\n",
      "Epoch 261/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.5261 - val_acc: 0.8614\n",
      "Epoch 262/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.5263 - val_acc: 0.8614\n",
      "Epoch 263/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.5265 - val_acc: 0.8614\n",
      "Epoch 264/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.5266 - val_acc: 0.8614\n",
      "Epoch 265/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.5268 - val_acc: 0.8614\n",
      "Epoch 266/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 0.5270 - val_acc: 0.8614\n",
      "Epoch 267/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 0.5272 - val_acc: 0.8614\n",
      "Epoch 268/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 0.5274 - val_acc: 0.8614\n",
      "Epoch 269/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 0.5276 - val_acc: 0.8614\n",
      "Epoch 270/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 0.5278 - val_acc: 0.8614\n",
      "Epoch 271/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 0.5280 - val_acc: 0.8614\n",
      "Epoch 272/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 0.5281 - val_acc: 0.8614\n",
      "Epoch 273/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 0.5283 - val_acc: 0.8614\n",
      "Epoch 274/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5285 - val_acc: 0.8614\n",
      "Epoch 275/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5287 - val_acc: 0.8614\n",
      "Epoch 276/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5289 - val_acc: 0.8614\n",
      "Epoch 277/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5291 - val_acc: 0.8614\n",
      "Epoch 278/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5292 - val_acc: 0.8614\n",
      "Epoch 279/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.5294 - val_acc: 0.8614\n",
      "Epoch 280/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.5296 - val_acc: 0.8614\n",
      "Epoch 281/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.5298 - val_acc: 0.8614\n",
      "Epoch 282/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.5300 - val_acc: 0.8614\n",
      "Epoch 283/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.5302 - val_acc: 0.8614\n",
      "Epoch 284/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.5304 - val_acc: 0.8614\n",
      "Epoch 285/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.5306 - val_acc: 0.8614\n",
      "Epoch 286/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.5308 - val_acc: 0.8614\n",
      "Epoch 287/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.5309 - val_acc: 0.8614\n",
      "Epoch 288/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.5311 - val_acc: 0.8614\n",
      "Epoch 289/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.5313 - val_acc: 0.8632\n",
      "Epoch 290/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.5315 - val_acc: 0.8632\n",
      "Epoch 291/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.5317 - val_acc: 0.8632\n",
      "Epoch 292/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.5319 - val_acc: 0.8632\n",
      "Epoch 293/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.5320 - val_acc: 0.8632\n",
      "Epoch 294/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.5322 - val_acc: 0.8632\n",
      "Epoch 295/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.5324 - val_acc: 0.8632\n",
      "Epoch 296/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.5326 - val_acc: 0.8632\n",
      "Epoch 297/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.5328 - val_acc: 0.8632\n",
      "Epoch 298/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.5330 - val_acc: 0.8632\n",
      "Epoch 299/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5332 - val_acc: 0.8632\n",
      "Epoch 300/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5334 - val_acc: 0.8632\n",
      "Epoch 301/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5336 - val_acc: 0.8632\n",
      "Epoch 302/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5338 - val_acc: 0.8632\n",
      "Epoch 303/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5339 - val_acc: 0.8632\n",
      "Epoch 304/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5341 - val_acc: 0.8632\n",
      "Epoch 305/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5343 - val_acc: 0.8632\n",
      "Epoch 306/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5345 - val_acc: 0.8632\n",
      "Epoch 307/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5347 - val_acc: 0.8632\n",
      "Epoch 308/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5348 - val_acc: 0.8632\n",
      "Epoch 309/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5350 - val_acc: 0.8632\n",
      "Epoch 310/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5352 - val_acc: 0.8632\n",
      "Epoch 311/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5354 - val_acc: 0.8632\n",
      "Epoch 312/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5356 - val_acc: 0.8632\n",
      "Epoch 313/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5357 - val_acc: 0.8632\n",
      "Epoch 314/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5359 - val_acc: 0.8632\n",
      "Epoch 315/1000\n",
      "570/570 [==============================] - 0s 25us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5361 - val_acc: 0.8632\n",
      "Epoch 316/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5363 - val_acc: 0.8632\n",
      "Epoch 317/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5364 - val_acc: 0.8632\n",
      "Epoch 318/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5366 - val_acc: 0.8632\n",
      "Epoch 319/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5368 - val_acc: 0.8632\n",
      "Epoch 320/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5370 - val_acc: 0.8632\n",
      "Epoch 321/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5371 - val_acc: 0.8632\n",
      "Epoch 322/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5373 - val_acc: 0.8632\n",
      "Epoch 323/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5375 - val_acc: 0.8632\n",
      "Epoch 324/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5377 - val_acc: 0.8632\n",
      "Epoch 325/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5379 - val_acc: 0.8632\n",
      "Epoch 326/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5380 - val_acc: 0.8632\n",
      "Epoch 327/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5382 - val_acc: 0.8632\n",
      "Epoch 328/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5384 - val_acc: 0.8632\n",
      "Epoch 329/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5386 - val_acc: 0.8632\n",
      "Epoch 330/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5388 - val_acc: 0.8632\n",
      "Epoch 331/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5389 - val_acc: 0.8632\n",
      "Epoch 332/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5391 - val_acc: 0.8632\n",
      "Epoch 333/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5393 - val_acc: 0.8632\n",
      "Epoch 334/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5395 - val_acc: 0.8632\n",
      "Epoch 335/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5397 - val_acc: 0.8632\n",
      "Epoch 336/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5398 - val_acc: 0.8632\n",
      "Epoch 337/1000\n",
      "570/570 [==============================] - 0s 25us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5400 - val_acc: 0.8632\n",
      "Epoch 338/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5402 - val_acc: 0.8632\n",
      "Epoch 339/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5404 - val_acc: 0.8632\n",
      "Epoch 340/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5406 - val_acc: 0.8632\n",
      "Epoch 341/1000\n",
      "570/570 [==============================] - 0s 24us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5407 - val_acc: 0.8632\n",
      "Epoch 342/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5409 - val_acc: 0.8632\n",
      "Epoch 343/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5411 - val_acc: 0.8632\n",
      "Epoch 344/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5413 - val_acc: 0.8614\n",
      "Epoch 345/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5415 - val_acc: 0.8596\n",
      "Epoch 346/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5416 - val_acc: 0.8596\n",
      "Epoch 347/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5418 - val_acc: 0.8596\n",
      "Epoch 348/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5420 - val_acc: 0.8596\n",
      "Epoch 349/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5422 - val_acc: 0.8596\n",
      "Epoch 350/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5423 - val_acc: 0.8596\n",
      "Epoch 351/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5425 - val_acc: 0.8596\n",
      "Epoch 352/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5427 - val_acc: 0.8596\n",
      "Epoch 353/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5428 - val_acc: 0.8596\n",
      "Epoch 354/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5430 - val_acc: 0.8596\n",
      "Epoch 355/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5432 - val_acc: 0.8596\n",
      "Epoch 356/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5434 - val_acc: 0.8596\n",
      "Epoch 357/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5435 - val_acc: 0.8596\n",
      "Epoch 358/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5437 - val_acc: 0.8596\n",
      "Epoch 359/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5439 - val_acc: 0.8596\n",
      "Epoch 360/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5441 - val_acc: 0.8596\n",
      "Epoch 361/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5442 - val_acc: 0.8596\n",
      "Epoch 362/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5444 - val_acc: 0.8596\n",
      "Epoch 363/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5446 - val_acc: 0.8596\n",
      "Epoch 364/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5448 - val_acc: 0.8596\n",
      "Epoch 365/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5449 - val_acc: 0.8596\n",
      "Epoch 366/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5451 - val_acc: 0.8596\n",
      "Epoch 367/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5453 - val_acc: 0.8596\n",
      "Epoch 368/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5455 - val_acc: 0.8596\n",
      "Epoch 369/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5456 - val_acc: 0.8596\n",
      "Epoch 370/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5458 - val_acc: 0.8596\n",
      "Epoch 371/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5460 - val_acc: 0.8596\n",
      "Epoch 372/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5461 - val_acc: 0.8596\n",
      "Epoch 373/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5463 - val_acc: 0.8596\n",
      "Epoch 374/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5465 - val_acc: 0.8596\n",
      "Epoch 375/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5466 - val_acc: 0.8596\n",
      "Epoch 376/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5468 - val_acc: 0.8596\n",
      "Epoch 377/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5470 - val_acc: 0.8596\n",
      "Epoch 378/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5471 - val_acc: 0.8596\n",
      "Epoch 379/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5473 - val_acc: 0.8596\n",
      "Epoch 380/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5475 - val_acc: 0.8596\n",
      "Epoch 381/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5477 - val_acc: 0.8596\n",
      "Epoch 382/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5478 - val_acc: 0.8596\n",
      "Epoch 383/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5480 - val_acc: 0.8596\n",
      "Epoch 384/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5481 - val_acc: 0.8596\n",
      "Epoch 385/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5483 - val_acc: 0.8596\n",
      "Epoch 386/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5485 - val_acc: 0.8596\n",
      "Epoch 387/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5486 - val_acc: 0.8596\n",
      "Epoch 388/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5488 - val_acc: 0.8596\n",
      "Epoch 389/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5490 - val_acc: 0.8596\n",
      "Epoch 390/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5491 - val_acc: 0.8596\n",
      "Epoch 391/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5493 - val_acc: 0.8596\n",
      "Epoch 392/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5495 - val_acc: 0.8596\n",
      "Epoch 393/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5496 - val_acc: 0.8614\n",
      "Epoch 394/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5498 - val_acc: 0.8614\n",
      "Epoch 395/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5500 - val_acc: 0.8614\n",
      "Epoch 396/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5501 - val_acc: 0.8614\n",
      "Epoch 397/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5503 - val_acc: 0.8614\n",
      "Epoch 398/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5505 - val_acc: 0.8614\n",
      "Epoch 399/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5506 - val_acc: 0.8614\n",
      "Epoch 400/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5508 - val_acc: 0.8614\n",
      "Epoch 401/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5510 - val_acc: 0.8614\n",
      "Epoch 402/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5511 - val_acc: 0.8614\n",
      "Epoch 403/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5513 - val_acc: 0.8614\n",
      "Epoch 404/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5515 - val_acc: 0.8614\n",
      "Epoch 405/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5516 - val_acc: 0.8614\n",
      "Epoch 406/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5518 - val_acc: 0.8614\n",
      "Epoch 407/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5520 - val_acc: 0.8614\n",
      "Epoch 408/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5521 - val_acc: 0.8614\n",
      "Epoch 409/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5523 - val_acc: 0.8614\n",
      "Epoch 410/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5525 - val_acc: 0.8614\n",
      "Epoch 411/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5526 - val_acc: 0.8614\n",
      "Epoch 412/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5528 - val_acc: 0.8614\n",
      "Epoch 413/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5529 - val_acc: 0.8614\n",
      "Epoch 414/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5531 - val_acc: 0.8614\n",
      "Epoch 415/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5532 - val_acc: 0.8614\n",
      "Epoch 416/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5534 - val_acc: 0.8614\n",
      "Epoch 417/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5536 - val_acc: 0.8614\n",
      "Epoch 418/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5537 - val_acc: 0.8614\n",
      "Epoch 419/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5539 - val_acc: 0.8614\n",
      "Epoch 420/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5540 - val_acc: 0.8614\n",
      "Epoch 421/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5542 - val_acc: 0.8614\n",
      "Epoch 422/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5544 - val_acc: 0.8614\n",
      "Epoch 423/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5545 - val_acc: 0.8614\n",
      "Epoch 424/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5547 - val_acc: 0.8614\n",
      "Epoch 425/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5549 - val_acc: 0.8614\n",
      "Epoch 426/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5550 - val_acc: 0.8614\n",
      "Epoch 427/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5552 - val_acc: 0.8614\n",
      "Epoch 428/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5553 - val_acc: 0.8614\n",
      "Epoch 429/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5555 - val_acc: 0.8614\n",
      "Epoch 430/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5557 - val_acc: 0.8614\n",
      "Epoch 431/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5558 - val_acc: 0.8614\n",
      "Epoch 432/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5560 - val_acc: 0.8614\n",
      "Epoch 433/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5561 - val_acc: 0.8614\n",
      "Epoch 434/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5563 - val_acc: 0.8614\n",
      "Epoch 435/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5564 - val_acc: 0.8614\n",
      "Epoch 436/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5566 - val_acc: 0.8614\n",
      "Epoch 437/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5568 - val_acc: 0.8614\n",
      "Epoch 438/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5569 - val_acc: 0.8614\n",
      "Epoch 439/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5571 - val_acc: 0.8614\n",
      "Epoch 440/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5572 - val_acc: 0.8614\n",
      "Epoch 441/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5574 - val_acc: 0.8614\n",
      "Epoch 442/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5575 - val_acc: 0.8614\n",
      "Epoch 443/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5577 - val_acc: 0.8614\n",
      "Epoch 444/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5579 - val_acc: 0.8614\n",
      "Epoch 445/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5580 - val_acc: 0.8614\n",
      "Epoch 446/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5582 - val_acc: 0.8614\n",
      "Epoch 447/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5583 - val_acc: 0.8614\n",
      "Epoch 448/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5585 - val_acc: 0.8614\n",
      "Epoch 449/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5586 - val_acc: 0.8614\n",
      "Epoch 450/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5588 - val_acc: 0.8614\n",
      "Epoch 451/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5589 - val_acc: 0.8614\n",
      "Epoch 452/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5591 - val_acc: 0.8614\n",
      "Epoch 453/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5593 - val_acc: 0.8614\n",
      "Epoch 454/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5594 - val_acc: 0.8614\n",
      "Epoch 455/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5596 - val_acc: 0.8614\n",
      "Epoch 456/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5597 - val_acc: 0.8614\n",
      "Epoch 457/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5599 - val_acc: 0.8614\n",
      "Epoch 458/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5600 - val_acc: 0.8614\n",
      "Epoch 459/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5602 - val_acc: 0.8614\n",
      "Epoch 460/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5603 - val_acc: 0.8614\n",
      "Epoch 461/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5605 - val_acc: 0.8614\n",
      "Epoch 462/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5606 - val_acc: 0.8614\n",
      "Epoch 463/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5608 - val_acc: 0.8614\n",
      "Epoch 464/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5609 - val_acc: 0.8614\n",
      "Epoch 465/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5611 - val_acc: 0.8614\n",
      "Epoch 466/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5613 - val_acc: 0.8614\n",
      "Epoch 467/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5614 - val_acc: 0.8614\n",
      "Epoch 468/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5616 - val_acc: 0.8614\n",
      "Epoch 469/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5617 - val_acc: 0.8614\n",
      "Epoch 470/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5619 - val_acc: 0.8614\n",
      "Epoch 471/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5620 - val_acc: 0.8614\n",
      "Epoch 472/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5622 - val_acc: 0.8614\n",
      "Epoch 473/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5623 - val_acc: 0.8614\n",
      "Epoch 474/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5625 - val_acc: 0.8614\n",
      "Epoch 475/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5626 - val_acc: 0.8614\n",
      "Epoch 476/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5628 - val_acc: 0.8614\n",
      "Epoch 477/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5629 - val_acc: 0.8614\n",
      "Epoch 478/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5631 - val_acc: 0.8614\n",
      "Epoch 479/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5632 - val_acc: 0.8614\n",
      "Epoch 480/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5634 - val_acc: 0.8614\n",
      "Epoch 481/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5635 - val_acc: 0.8614\n",
      "Epoch 482/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5637 - val_acc: 0.8632\n",
      "Epoch 483/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5638 - val_acc: 0.8614\n",
      "Epoch 484/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5640 - val_acc: 0.8614\n",
      "Epoch 485/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5641 - val_acc: 0.8632\n",
      "Epoch 486/1000\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.000 - 0s 19us/sample - loss: 9.9716e-04 - acc: 1.0000 - val_loss: 0.5643 - val_acc: 0.8632\n",
      "Epoch 487/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 9.9296e-04 - acc: 1.0000 - val_loss: 0.5644 - val_acc: 0.8632\n",
      "Epoch 488/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 9.8875e-04 - acc: 1.0000 - val_loss: 0.5646 - val_acc: 0.8632\n",
      "Epoch 489/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 9.8454e-04 - acc: 1.0000 - val_loss: 0.5647 - val_acc: 0.8632\n",
      "Epoch 490/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 9.8045e-04 - acc: 1.0000 - val_loss: 0.5649 - val_acc: 0.8632\n",
      "Epoch 491/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 9.7626e-04 - acc: 1.0000 - val_loss: 0.5650 - val_acc: 0.8632\n",
      "Epoch 492/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 9.7225e-04 - acc: 1.0000 - val_loss: 0.5652 - val_acc: 0.8632\n",
      "Epoch 493/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 9.6816e-04 - acc: 1.0000 - val_loss: 0.5653 - val_acc: 0.8632\n",
      "Epoch 494/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 9.6412e-04 - acc: 1.0000 - val_loss: 0.5655 - val_acc: 0.8632\n",
      "Epoch 495/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 9.6005e-04 - acc: 1.0000 - val_loss: 0.5656 - val_acc: 0.8632\n",
      "Epoch 496/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 9.5616e-04 - acc: 1.0000 - val_loss: 0.5658 - val_acc: 0.8632\n",
      "Epoch 497/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 9.5214e-04 - acc: 1.0000 - val_loss: 0.5659 - val_acc: 0.8632\n",
      "Epoch 498/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 9.4826e-04 - acc: 1.0000 - val_loss: 0.5661 - val_acc: 0.8632\n",
      "Epoch 499/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 9.4426e-04 - acc: 1.0000 - val_loss: 0.5662 - val_acc: 0.8632\n",
      "Epoch 500/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 9.4042e-04 - acc: 1.0000 - val_loss: 0.5664 - val_acc: 0.8632\n",
      "Epoch 501/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 9.3647e-04 - acc: 1.0000 - val_loss: 0.5665 - val_acc: 0.8632\n",
      "Epoch 502/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 9.3273e-04 - acc: 1.0000 - val_loss: 0.5667 - val_acc: 0.8632\n",
      "Epoch 503/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 9.2882e-04 - acc: 1.0000 - val_loss: 0.5668 - val_acc: 0.8632\n",
      "Epoch 504/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 9.2505e-04 - acc: 1.0000 - val_loss: 0.5669 - val_acc: 0.8632\n",
      "Epoch 505/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 9.2123e-04 - acc: 1.0000 - val_loss: 0.5671 - val_acc: 0.8632\n",
      "Epoch 506/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 9.1742e-04 - acc: 1.0000 - val_loss: 0.5672 - val_acc: 0.8632\n",
      "Epoch 507/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 9.1373e-04 - acc: 1.0000 - val_loss: 0.5674 - val_acc: 0.8632\n",
      "Epoch 508/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 9.0996e-04 - acc: 1.0000 - val_loss: 0.5675 - val_acc: 0.8632\n",
      "Epoch 509/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 9.0626e-04 - acc: 1.0000 - val_loss: 0.5677 - val_acc: 0.8632\n",
      "Epoch 510/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 9.0261e-04 - acc: 1.0000 - val_loss: 0.5678 - val_acc: 0.8632\n",
      "Epoch 511/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 8.9905e-04 - acc: 1.0000 - val_loss: 0.5680 - val_acc: 0.8632\n",
      "Epoch 512/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 8.9529e-04 - acc: 1.0000 - val_loss: 0.5681 - val_acc: 0.8632\n",
      "Epoch 513/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 8.9171e-04 - acc: 1.0000 - val_loss: 0.5683 - val_acc: 0.8632\n",
      "Epoch 514/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 8.8811e-04 - acc: 1.0000 - val_loss: 0.5684 - val_acc: 0.8632\n",
      "Epoch 515/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 8.8458e-04 - acc: 1.0000 - val_loss: 0.5686 - val_acc: 0.8632\n",
      "Epoch 516/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 8.8102e-04 - acc: 1.0000 - val_loss: 0.5687 - val_acc: 0.8632\n",
      "Epoch 517/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 8.7742e-04 - acc: 1.0000 - val_loss: 0.5688 - val_acc: 0.8632\n",
      "Epoch 518/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 8.7398e-04 - acc: 1.0000 - val_loss: 0.5690 - val_acc: 0.8632\n",
      "Epoch 519/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 8.7051e-04 - acc: 1.0000 - val_loss: 0.5691 - val_acc: 0.8632\n",
      "Epoch 520/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 8.6700e-04 - acc: 1.0000 - val_loss: 0.5693 - val_acc: 0.8632\n",
      "Epoch 521/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 8.6357e-04 - acc: 1.0000 - val_loss: 0.5694 - val_acc: 0.8632\n",
      "Epoch 522/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 8.6010e-04 - acc: 1.0000 - val_loss: 0.5696 - val_acc: 0.8632\n",
      "Epoch 523/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 8.5669e-04 - acc: 1.0000 - val_loss: 0.5697 - val_acc: 0.8632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 524/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 8.5329e-04 - acc: 1.0000 - val_loss: 0.5698 - val_acc: 0.8632\n",
      "Epoch 525/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 8.4992e-04 - acc: 1.0000 - val_loss: 0.5700 - val_acc: 0.8632\n",
      "Epoch 526/1000\n",
      "570/570 [==============================] - 0s 24us/sample - loss: 8.4664e-04 - acc: 1.0000 - val_loss: 0.5701 - val_acc: 0.8632\n",
      "Epoch 527/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 8.4329e-04 - acc: 1.0000 - val_loss: 0.5703 - val_acc: 0.8649\n",
      "Epoch 528/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 8.3992e-04 - acc: 1.0000 - val_loss: 0.5704 - val_acc: 0.8649\n",
      "Epoch 529/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 8.3663e-04 - acc: 1.0000 - val_loss: 0.5705 - val_acc: 0.8649\n",
      "Epoch 530/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 8.3333e-04 - acc: 1.0000 - val_loss: 0.5707 - val_acc: 0.8649\n",
      "Epoch 531/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 8.3006e-04 - acc: 1.0000 - val_loss: 0.5708 - val_acc: 0.8649\n",
      "Epoch 532/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 8.2682e-04 - acc: 1.0000 - val_loss: 0.5710 - val_acc: 0.8649\n",
      "Epoch 533/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 8.2367e-04 - acc: 1.0000 - val_loss: 0.5711 - val_acc: 0.8649\n",
      "Epoch 534/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 8.2038e-04 - acc: 1.0000 - val_loss: 0.5713 - val_acc: 0.8649\n",
      "Epoch 535/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 8.1722e-04 - acc: 1.0000 - val_loss: 0.5714 - val_acc: 0.8649\n",
      "Epoch 536/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 8.1406e-04 - acc: 1.0000 - val_loss: 0.5715 - val_acc: 0.8649\n",
      "Epoch 537/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 8.1082e-04 - acc: 1.0000 - val_loss: 0.5717 - val_acc: 0.8649\n",
      "Epoch 538/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 8.0777e-04 - acc: 1.0000 - val_loss: 0.5718 - val_acc: 0.8649\n",
      "Epoch 539/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 8.0459e-04 - acc: 1.0000 - val_loss: 0.5720 - val_acc: 0.8649\n",
      "Epoch 540/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 8.0145e-04 - acc: 1.0000 - val_loss: 0.5721 - val_acc: 0.8649\n",
      "Epoch 541/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.9846e-04 - acc: 1.0000 - val_loss: 0.5723 - val_acc: 0.8649\n",
      "Epoch 542/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 7.9531e-04 - acc: 1.0000 - val_loss: 0.5724 - val_acc: 0.8649\n",
      "Epoch 543/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 7.9230e-04 - acc: 1.0000 - val_loss: 0.5725 - val_acc: 0.8649\n",
      "Epoch 544/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 7.8917e-04 - acc: 1.0000 - val_loss: 0.5727 - val_acc: 0.8649\n",
      "Epoch 545/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.8627e-04 - acc: 1.0000 - val_loss: 0.5728 - val_acc: 0.8649\n",
      "Epoch 546/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.8317e-04 - acc: 1.0000 - val_loss: 0.5730 - val_acc: 0.8649\n",
      "Epoch 547/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.8015e-04 - acc: 1.0000 - val_loss: 0.5731 - val_acc: 0.8649\n",
      "Epoch 548/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 7.7719e-04 - acc: 1.0000 - val_loss: 0.5732 - val_acc: 0.8649\n",
      "Epoch 549/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 7.7426e-04 - acc: 1.0000 - val_loss: 0.5734 - val_acc: 0.8649\n",
      "Epoch 550/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 7.7143e-04 - acc: 1.0000 - val_loss: 0.5735 - val_acc: 0.8649\n",
      "Epoch 551/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 7.6839e-04 - acc: 1.0000 - val_loss: 0.5737 - val_acc: 0.8649\n",
      "Epoch 552/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.6548e-04 - acc: 1.0000 - val_loss: 0.5738 - val_acc: 0.8649\n",
      "Epoch 553/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.6255e-04 - acc: 1.0000 - val_loss: 0.5739 - val_acc: 0.8649\n",
      "Epoch 554/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.5969e-04 - acc: 1.0000 - val_loss: 0.5741 - val_acc: 0.8649\n",
      "Epoch 555/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.5681e-04 - acc: 1.0000 - val_loss: 0.5742 - val_acc: 0.8649\n",
      "Epoch 556/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 7.5399e-04 - acc: 1.0000 - val_loss: 0.5743 - val_acc: 0.8649\n",
      "Epoch 557/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 7.5107e-04 - acc: 1.0000 - val_loss: 0.5745 - val_acc: 0.8649\n",
      "Epoch 558/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.4835e-04 - acc: 1.0000 - val_loss: 0.5746 - val_acc: 0.8649\n",
      "Epoch 559/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 7.4551e-04 - acc: 1.0000 - val_loss: 0.5748 - val_acc: 0.8649\n",
      "Epoch 560/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 7.4272e-04 - acc: 1.0000 - val_loss: 0.5749 - val_acc: 0.8649\n",
      "Epoch 561/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.3988e-04 - acc: 1.0000 - val_loss: 0.5751 - val_acc: 0.8649\n",
      "Epoch 562/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.3719e-04 - acc: 1.0000 - val_loss: 0.5752 - val_acc: 0.8649\n",
      "Epoch 563/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 7.3446e-04 - acc: 1.0000 - val_loss: 0.5753 - val_acc: 0.8649\n",
      "Epoch 564/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 7.3167e-04 - acc: 1.0000 - val_loss: 0.5755 - val_acc: 0.8649\n",
      "Epoch 565/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 7.2892e-04 - acc: 1.0000 - val_loss: 0.5756 - val_acc: 0.8649\n",
      "Epoch 566/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 7.2626e-04 - acc: 1.0000 - val_loss: 0.5758 - val_acc: 0.8649\n",
      "Epoch 567/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.2348e-04 - acc: 1.0000 - val_loss: 0.5759 - val_acc: 0.8649\n",
      "Epoch 568/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.2087e-04 - acc: 1.0000 - val_loss: 0.5760 - val_acc: 0.8649\n",
      "Epoch 569/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.1819e-04 - acc: 1.0000 - val_loss: 0.5762 - val_acc: 0.8649\n",
      "Epoch 570/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.1555e-04 - acc: 1.0000 - val_loss: 0.5763 - val_acc: 0.8649\n",
      "Epoch 571/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 7.1290e-04 - acc: 1.0000 - val_loss: 0.5764 - val_acc: 0.8649\n",
      "Epoch 572/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.1028e-04 - acc: 1.0000 - val_loss: 0.5766 - val_acc: 0.8649\n",
      "Epoch 573/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 7.0769e-04 - acc: 1.0000 - val_loss: 0.5767 - val_acc: 0.8649\n",
      "Epoch 574/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 7.0502e-04 - acc: 1.0000 - val_loss: 0.5769 - val_acc: 0.8649\n",
      "Epoch 575/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 7.0252e-04 - acc: 1.0000 - val_loss: 0.5770 - val_acc: 0.8649\n",
      "Epoch 576/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 6.9989e-04 - acc: 1.0000 - val_loss: 0.5771 - val_acc: 0.8649\n",
      "Epoch 577/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.9737e-04 - acc: 1.0000 - val_loss: 0.5773 - val_acc: 0.8649\n",
      "Epoch 578/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.9476e-04 - acc: 1.0000 - val_loss: 0.5774 - val_acc: 0.8649\n",
      "Epoch 579/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 6.9229e-04 - acc: 1.0000 - val_loss: 0.5775 - val_acc: 0.8649\n",
      "Epoch 580/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 6.8973e-04 - acc: 1.0000 - val_loss: 0.5777 - val_acc: 0.8649\n",
      "Epoch 581/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 21us/sample - loss: 6.8727e-04 - acc: 1.0000 - val_loss: 0.5778 - val_acc: 0.8649\n",
      "Epoch 582/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.8475e-04 - acc: 1.0000 - val_loss: 0.5780 - val_acc: 0.8649\n",
      "Epoch 583/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 6.8227e-04 - acc: 1.0000 - val_loss: 0.5781 - val_acc: 0.8649\n",
      "Epoch 584/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 6.7985e-04 - acc: 1.0000 - val_loss: 0.5782 - val_acc: 0.8649\n",
      "Epoch 585/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 6.7734e-04 - acc: 1.0000 - val_loss: 0.5784 - val_acc: 0.8649\n",
      "Epoch 586/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 6.7490e-04 - acc: 1.0000 - val_loss: 0.5785 - val_acc: 0.8649\n",
      "Epoch 587/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 6.7248e-04 - acc: 1.0000 - val_loss: 0.5786 - val_acc: 0.8649\n",
      "Epoch 588/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.7002e-04 - acc: 1.0000 - val_loss: 0.5788 - val_acc: 0.8649\n",
      "Epoch 589/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 6.6764e-04 - acc: 1.0000 - val_loss: 0.5789 - val_acc: 0.8649\n",
      "Epoch 590/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 6.6520e-04 - acc: 1.0000 - val_loss: 0.5790 - val_acc: 0.8649\n",
      "Epoch 591/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 6.6287e-04 - acc: 1.0000 - val_loss: 0.5792 - val_acc: 0.8649\n",
      "Epoch 592/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 6.6046e-04 - acc: 1.0000 - val_loss: 0.5793 - val_acc: 0.8649\n",
      "Epoch 593/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 6.5813e-04 - acc: 1.0000 - val_loss: 0.5794 - val_acc: 0.8649\n",
      "Epoch 594/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.5572e-04 - acc: 1.0000 - val_loss: 0.5796 - val_acc: 0.8649\n",
      "Epoch 595/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.5348e-04 - acc: 1.0000 - val_loss: 0.5797 - val_acc: 0.8649\n",
      "Epoch 596/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.5115e-04 - acc: 1.0000 - val_loss: 0.5798 - val_acc: 0.8649\n",
      "Epoch 597/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 6.4879e-04 - acc: 1.0000 - val_loss: 0.5800 - val_acc: 0.8649\n",
      "Epoch 598/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.4648e-04 - acc: 1.0000 - val_loss: 0.5801 - val_acc: 0.8649\n",
      "Epoch 599/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 6.4422e-04 - acc: 1.0000 - val_loss: 0.5802 - val_acc: 0.8649\n",
      "Epoch 600/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 6.4193e-04 - acc: 1.0000 - val_loss: 0.5804 - val_acc: 0.8649\n",
      "Epoch 601/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.3966e-04 - acc: 1.0000 - val_loss: 0.5805 - val_acc: 0.8649\n",
      "Epoch 602/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 6.3740e-04 - acc: 1.0000 - val_loss: 0.5806 - val_acc: 0.8649\n",
      "Epoch 603/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.3514e-04 - acc: 1.0000 - val_loss: 0.5808 - val_acc: 0.8649\n",
      "Epoch 604/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.3295e-04 - acc: 1.0000 - val_loss: 0.5809 - val_acc: 0.8649\n",
      "Epoch 605/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 6.3071e-04 - acc: 1.0000 - val_loss: 0.5810 - val_acc: 0.8649\n",
      "Epoch 606/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 6.2853e-04 - acc: 1.0000 - val_loss: 0.5812 - val_acc: 0.8649\n",
      "Epoch 607/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.2627e-04 - acc: 1.0000 - val_loss: 0.5813 - val_acc: 0.8649\n",
      "Epoch 608/1000\n",
      "570/570 [==============================] - 0s 24us/sample - loss: 6.2411e-04 - acc: 1.0000 - val_loss: 0.5814 - val_acc: 0.8649\n",
      "Epoch 609/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.2191e-04 - acc: 1.0000 - val_loss: 0.5816 - val_acc: 0.8649\n",
      "Epoch 610/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 6.1977e-04 - acc: 1.0000 - val_loss: 0.5817 - val_acc: 0.8649\n",
      "Epoch 611/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.1758e-04 - acc: 1.0000 - val_loss: 0.5818 - val_acc: 0.8649\n",
      "Epoch 612/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.1545e-04 - acc: 1.0000 - val_loss: 0.5820 - val_acc: 0.8649\n",
      "Epoch 613/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 6.1331e-04 - acc: 1.0000 - val_loss: 0.5821 - val_acc: 0.8649\n",
      "Epoch 614/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 6.1120e-04 - acc: 1.0000 - val_loss: 0.5822 - val_acc: 0.8649\n",
      "Epoch 615/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.0903e-04 - acc: 1.0000 - val_loss: 0.5823 - val_acc: 0.8649\n",
      "Epoch 616/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 6.0697e-04 - acc: 1.0000 - val_loss: 0.5825 - val_acc: 0.8649\n",
      "Epoch 617/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 6.0481e-04 - acc: 1.0000 - val_loss: 0.5826 - val_acc: 0.8649\n",
      "Epoch 618/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 6.0277e-04 - acc: 1.0000 - val_loss: 0.5827 - val_acc: 0.8649\n",
      "Epoch 619/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 6.0068e-04 - acc: 1.0000 - val_loss: 0.5829 - val_acc: 0.8649\n",
      "Epoch 620/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.9859e-04 - acc: 1.0000 - val_loss: 0.5830 - val_acc: 0.8649\n",
      "Epoch 621/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.9654e-04 - acc: 1.0000 - val_loss: 0.5831 - val_acc: 0.8649\n",
      "Epoch 622/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.9449e-04 - acc: 1.0000 - val_loss: 0.5832 - val_acc: 0.8649\n",
      "Epoch 623/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 5.9249e-04 - acc: 1.0000 - val_loss: 0.5834 - val_acc: 0.8649\n",
      "Epoch 624/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 5.9041e-04 - acc: 1.0000 - val_loss: 0.5835 - val_acc: 0.8649\n",
      "Epoch 625/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.8841e-04 - acc: 1.0000 - val_loss: 0.5836 - val_acc: 0.8649\n",
      "Epoch 626/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.8645e-04 - acc: 1.0000 - val_loss: 0.5838 - val_acc: 0.8649\n",
      "Epoch 627/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.8440e-04 - acc: 1.0000 - val_loss: 0.5839 - val_acc: 0.8667\n",
      "Epoch 628/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 5.8239e-04 - acc: 1.0000 - val_loss: 0.5840 - val_acc: 0.8667\n",
      "Epoch 629/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.8042e-04 - acc: 1.0000 - val_loss: 0.5841 - val_acc: 0.8667\n",
      "Epoch 630/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.7846e-04 - acc: 1.0000 - val_loss: 0.5843 - val_acc: 0.8667\n",
      "Epoch 631/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.7647e-04 - acc: 1.0000 - val_loss: 0.5844 - val_acc: 0.8667\n",
      "Epoch 632/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 5.7455e-04 - acc: 1.0000 - val_loss: 0.5845 - val_acc: 0.8667\n",
      "Epoch 633/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.7258e-04 - acc: 1.0000 - val_loss: 0.5847 - val_acc: 0.8667\n",
      "Epoch 634/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.7066e-04 - acc: 1.0000 - val_loss: 0.5848 - val_acc: 0.8667\n",
      "Epoch 635/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 5.6875e-04 - acc: 1.0000 - val_loss: 0.5849 - val_acc: 0.8667\n",
      "Epoch 636/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.6679e-04 - acc: 1.0000 - val_loss: 0.5851 - val_acc: 0.8667\n",
      "Epoch 637/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.6491e-04 - acc: 1.0000 - val_loss: 0.5852 - val_acc: 0.8667\n",
      "Epoch 638/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 19us/sample - loss: 5.6297e-04 - acc: 1.0000 - val_loss: 0.5853 - val_acc: 0.8667\n",
      "Epoch 639/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.6115e-04 - acc: 1.0000 - val_loss: 0.5855 - val_acc: 0.8667\n",
      "Epoch 640/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.5922e-04 - acc: 1.0000 - val_loss: 0.5856 - val_acc: 0.8667\n",
      "Epoch 641/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 5.5733e-04 - acc: 1.0000 - val_loss: 0.5857 - val_acc: 0.8667\n",
      "Epoch 642/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 5.5544e-04 - acc: 1.0000 - val_loss: 0.5859 - val_acc: 0.8667\n",
      "Epoch 643/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.5362e-04 - acc: 1.0000 - val_loss: 0.5860 - val_acc: 0.8667\n",
      "Epoch 644/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 5.5174e-04 - acc: 1.0000 - val_loss: 0.5861 - val_acc: 0.8667\n",
      "Epoch 645/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 5.4988e-04 - acc: 1.0000 - val_loss: 0.5862 - val_acc: 0.8667\n",
      "Epoch 646/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.4809e-04 - acc: 1.0000 - val_loss: 0.5864 - val_acc: 0.8667\n",
      "Epoch 647/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.4626e-04 - acc: 1.0000 - val_loss: 0.5865 - val_acc: 0.8667\n",
      "Epoch 648/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.4440e-04 - acc: 1.0000 - val_loss: 0.5866 - val_acc: 0.8667\n",
      "Epoch 649/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.4262e-04 - acc: 1.0000 - val_loss: 0.5868 - val_acc: 0.8667\n",
      "Epoch 650/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.4083e-04 - acc: 1.0000 - val_loss: 0.5869 - val_acc: 0.8667\n",
      "Epoch 651/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.3897e-04 - acc: 1.0000 - val_loss: 0.5870 - val_acc: 0.8667\n",
      "Epoch 652/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.3722e-04 - acc: 1.0000 - val_loss: 0.5871 - val_acc: 0.8667\n",
      "Epoch 653/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 5.3546e-04 - acc: 1.0000 - val_loss: 0.5873 - val_acc: 0.8667\n",
      "Epoch 654/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.3372e-04 - acc: 1.0000 - val_loss: 0.5874 - val_acc: 0.8667\n",
      "Epoch 655/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 5.3192e-04 - acc: 1.0000 - val_loss: 0.5875 - val_acc: 0.8667\n",
      "Epoch 656/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.3018e-04 - acc: 1.0000 - val_loss: 0.5877 - val_acc: 0.8667\n",
      "Epoch 657/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.2842e-04 - acc: 1.0000 - val_loss: 0.5878 - val_acc: 0.8667\n",
      "Epoch 658/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.2671e-04 - acc: 1.0000 - val_loss: 0.5879 - val_acc: 0.8667\n",
      "Epoch 659/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.2501e-04 - acc: 1.0000 - val_loss: 0.5880 - val_acc: 0.8667\n",
      "Epoch 660/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 5.2325e-04 - acc: 1.0000 - val_loss: 0.5882 - val_acc: 0.8667\n",
      "Epoch 661/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.2157e-04 - acc: 1.0000 - val_loss: 0.5883 - val_acc: 0.8667\n",
      "Epoch 662/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.1988e-04 - acc: 1.0000 - val_loss: 0.5884 - val_acc: 0.8667\n",
      "Epoch 663/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.1815e-04 - acc: 1.0000 - val_loss: 0.5886 - val_acc: 0.8667\n",
      "Epoch 664/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.1644e-04 - acc: 1.0000 - val_loss: 0.5887 - val_acc: 0.8667\n",
      "Epoch 665/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.1479e-04 - acc: 1.0000 - val_loss: 0.5888 - val_acc: 0.8667\n",
      "Epoch 666/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.1311e-04 - acc: 1.0000 - val_loss: 0.5889 - val_acc: 0.8667\n",
      "Epoch 667/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.1145e-04 - acc: 1.0000 - val_loss: 0.5891 - val_acc: 0.8667\n",
      "Epoch 668/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.0976e-04 - acc: 1.0000 - val_loss: 0.5892 - val_acc: 0.8667\n",
      "Epoch 669/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 5.0810e-04 - acc: 1.0000 - val_loss: 0.5893 - val_acc: 0.8667\n",
      "Epoch 670/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.0645e-04 - acc: 1.0000 - val_loss: 0.5894 - val_acc: 0.8667\n",
      "Epoch 671/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 5.0483e-04 - acc: 1.0000 - val_loss: 0.5896 - val_acc: 0.8667\n",
      "Epoch 672/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.0324e-04 - acc: 1.0000 - val_loss: 0.5897 - val_acc: 0.8667\n",
      "Epoch 673/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 5.0156e-04 - acc: 1.0000 - val_loss: 0.5898 - val_acc: 0.8667\n",
      "Epoch 674/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.9995e-04 - acc: 1.0000 - val_loss: 0.5899 - val_acc: 0.8667\n",
      "Epoch 675/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 4.9832e-04 - acc: 1.0000 - val_loss: 0.5901 - val_acc: 0.8667\n",
      "Epoch 676/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.9670e-04 - acc: 1.0000 - val_loss: 0.5902 - val_acc: 0.8667\n",
      "Epoch 677/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.9513e-04 - acc: 1.0000 - val_loss: 0.5903 - val_acc: 0.8667\n",
      "Epoch 678/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.9355e-04 - acc: 1.0000 - val_loss: 0.5905 - val_acc: 0.8667\n",
      "Epoch 679/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.9195e-04 - acc: 1.0000 - val_loss: 0.5906 - val_acc: 0.8667\n",
      "Epoch 680/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 4.9037e-04 - acc: 1.0000 - val_loss: 0.5907 - val_acc: 0.8649\n",
      "Epoch 681/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.8881e-04 - acc: 1.0000 - val_loss: 0.5908 - val_acc: 0.8649\n",
      "Epoch 682/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 4.8723e-04 - acc: 1.0000 - val_loss: 0.5910 - val_acc: 0.8649\n",
      "Epoch 683/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 4.8569e-04 - acc: 1.0000 - val_loss: 0.5911 - val_acc: 0.8649\n",
      "Epoch 684/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 4.8412e-04 - acc: 1.0000 - val_loss: 0.5912 - val_acc: 0.8667\n",
      "Epoch 685/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.8257e-04 - acc: 1.0000 - val_loss: 0.5913 - val_acc: 0.8667\n",
      "Epoch 686/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.8104e-04 - acc: 1.0000 - val_loss: 0.5914 - val_acc: 0.8667\n",
      "Epoch 687/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 4.7951e-04 - acc: 1.0000 - val_loss: 0.5916 - val_acc: 0.8667\n",
      "Epoch 688/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.7801e-04 - acc: 1.0000 - val_loss: 0.5917 - val_acc: 0.8667\n",
      "Epoch 689/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.7649e-04 - acc: 1.0000 - val_loss: 0.5918 - val_acc: 0.8667\n",
      "Epoch 690/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.7494e-04 - acc: 1.0000 - val_loss: 0.5919 - val_acc: 0.8667\n",
      "Epoch 691/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 4.7343e-04 - acc: 1.0000 - val_loss: 0.5921 - val_acc: 0.8667\n",
      "Epoch 692/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.7195e-04 - acc: 1.0000 - val_loss: 0.5922 - val_acc: 0.8667\n",
      "Epoch 693/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.7048e-04 - acc: 1.0000 - val_loss: 0.5923 - val_acc: 0.8667\n",
      "Epoch 694/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 4.6897e-04 - acc: 1.0000 - val_loss: 0.5924 - val_acc: 0.8667\n",
      "Epoch 695/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 21us/sample - loss: 4.6752e-04 - acc: 1.0000 - val_loss: 0.5925 - val_acc: 0.8667\n",
      "Epoch 696/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.6600e-04 - acc: 1.0000 - val_loss: 0.5926 - val_acc: 0.8667\n",
      "Epoch 697/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 4.6457e-04 - acc: 1.0000 - val_loss: 0.5927 - val_acc: 0.8684\n",
      "Epoch 698/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 4.6310e-04 - acc: 1.0000 - val_loss: 0.5929 - val_acc: 0.8684\n",
      "Epoch 699/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.6165e-04 - acc: 1.0000 - val_loss: 0.5930 - val_acc: 0.8684\n",
      "Epoch 700/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 4.6022e-04 - acc: 1.0000 - val_loss: 0.5931 - val_acc: 0.8684\n",
      "Epoch 701/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.5873e-04 - acc: 1.0000 - val_loss: 0.5932 - val_acc: 0.8684\n",
      "Epoch 702/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.5731e-04 - acc: 1.0000 - val_loss: 0.5933 - val_acc: 0.8684\n",
      "Epoch 703/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.5591e-04 - acc: 1.0000 - val_loss: 0.5934 - val_acc: 0.8684\n",
      "Epoch 704/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 4.5446e-04 - acc: 1.0000 - val_loss: 0.5935 - val_acc: 0.8684\n",
      "Epoch 705/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 4.5301e-04 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.8684\n",
      "Epoch 706/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.5162e-04 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.8684\n",
      "Epoch 707/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 4.5021e-04 - acc: 1.0000 - val_loss: 0.5939 - val_acc: 0.8684\n",
      "Epoch 708/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 4.4882e-04 - acc: 1.0000 - val_loss: 0.5940 - val_acc: 0.8684\n",
      "Epoch 709/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 4.4744e-04 - acc: 1.0000 - val_loss: 0.5941 - val_acc: 0.8684\n",
      "Epoch 710/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.4603e-04 - acc: 1.0000 - val_loss: 0.5942 - val_acc: 0.8684\n",
      "Epoch 711/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.4465e-04 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.8684\n",
      "Epoch 712/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.4331e-04 - acc: 1.0000 - val_loss: 0.5944 - val_acc: 0.8684\n",
      "Epoch 713/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.4190e-04 - acc: 1.0000 - val_loss: 0.5945 - val_acc: 0.8684\n",
      "Epoch 714/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 4.4053e-04 - acc: 1.0000 - val_loss: 0.5946 - val_acc: 0.8684\n",
      "Epoch 715/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.3917e-04 - acc: 1.0000 - val_loss: 0.5948 - val_acc: 0.8684\n",
      "Epoch 716/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.3779e-04 - acc: 1.0000 - val_loss: 0.5949 - val_acc: 0.8684\n",
      "Epoch 717/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.3646e-04 - acc: 1.0000 - val_loss: 0.5950 - val_acc: 0.8684\n",
      "Epoch 718/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.3514e-04 - acc: 1.0000 - val_loss: 0.5951 - val_acc: 0.8684\n",
      "Epoch 719/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.3378e-04 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.8684\n",
      "Epoch 720/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.3245e-04 - acc: 1.0000 - val_loss: 0.5953 - val_acc: 0.8684\n",
      "Epoch 721/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 4.3113e-04 - acc: 1.0000 - val_loss: 0.5954 - val_acc: 0.8684\n",
      "Epoch 722/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.2983e-04 - acc: 1.0000 - val_loss: 0.5955 - val_acc: 0.8684\n",
      "Epoch 723/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.2848e-04 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.8684\n",
      "Epoch 724/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.2718e-04 - acc: 1.0000 - val_loss: 0.5957 - val_acc: 0.8684\n",
      "Epoch 725/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.2587e-04 - acc: 1.0000 - val_loss: 0.5958 - val_acc: 0.8684\n",
      "Epoch 726/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 4.2460e-04 - acc: 1.0000 - val_loss: 0.5959 - val_acc: 0.8684\n",
      "Epoch 727/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.2326e-04 - acc: 1.0000 - val_loss: 0.5960 - val_acc: 0.8684\n",
      "Epoch 728/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 4.2200e-04 - acc: 1.0000 - val_loss: 0.5961 - val_acc: 0.8702\n",
      "Epoch 729/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.2067e-04 - acc: 1.0000 - val_loss: 0.5962 - val_acc: 0.8702\n",
      "Epoch 730/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.1943e-04 - acc: 1.0000 - val_loss: 0.5963 - val_acc: 0.8702\n",
      "Epoch 731/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.1817e-04 - acc: 1.0000 - val_loss: 0.5964 - val_acc: 0.8702\n",
      "Epoch 732/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.1689e-04 - acc: 1.0000 - val_loss: 0.5965 - val_acc: 0.8702\n",
      "Epoch 733/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.1563e-04 - acc: 1.0000 - val_loss: 0.5966 - val_acc: 0.8702\n",
      "Epoch 734/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.1437e-04 - acc: 1.0000 - val_loss: 0.5967 - val_acc: 0.8702\n",
      "Epoch 735/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 4.1309e-04 - acc: 1.0000 - val_loss: 0.5968 - val_acc: 0.8702\n",
      "Epoch 736/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 4.1188e-04 - acc: 1.0000 - val_loss: 0.5969 - val_acc: 0.8702\n",
      "Epoch 737/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.1062e-04 - acc: 1.0000 - val_loss: 0.5970 - val_acc: 0.8702\n",
      "Epoch 738/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 4.0938e-04 - acc: 1.0000 - val_loss: 0.5971 - val_acc: 0.8702\n",
      "Epoch 739/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.0816e-04 - acc: 1.0000 - val_loss: 0.5972 - val_acc: 0.8702\n",
      "Epoch 740/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 4.0691e-04 - acc: 1.0000 - val_loss: 0.5974 - val_acc: 0.8702\n",
      "Epoch 741/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 4.0571e-04 - acc: 1.0000 - val_loss: 0.5975 - val_acc: 0.8702\n",
      "Epoch 742/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 4.0447e-04 - acc: 1.0000 - val_loss: 0.5976 - val_acc: 0.8702\n",
      "Epoch 743/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 4.0325e-04 - acc: 1.0000 - val_loss: 0.5977 - val_acc: 0.8702\n",
      "Epoch 744/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 4.0206e-04 - acc: 1.0000 - val_loss: 0.5978 - val_acc: 0.8702\n",
      "Epoch 745/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 4.0086e-04 - acc: 1.0000 - val_loss: 0.5979 - val_acc: 0.8702\n",
      "Epoch 746/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 3.9964e-04 - acc: 1.0000 - val_loss: 0.5980 - val_acc: 0.8702\n",
      "Epoch 747/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.9849e-04 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.8702\n",
      "Epoch 748/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 3.9728e-04 - acc: 1.0000 - val_loss: 0.5982 - val_acc: 0.8702\n",
      "Epoch 749/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.9608e-04 - acc: 1.0000 - val_loss: 0.5983 - val_acc: 0.8702\n",
      "Epoch 750/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.9490e-04 - acc: 1.0000 - val_loss: 0.5984 - val_acc: 0.8702\n",
      "Epoch 751/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 3.9374e-04 - acc: 1.0000 - val_loss: 0.5985 - val_acc: 0.8702\n",
      "Epoch 752/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 20us/sample - loss: 3.9254e-04 - acc: 1.0000 - val_loss: 0.5986 - val_acc: 0.8702\n",
      "Epoch 753/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.9140e-04 - acc: 1.0000 - val_loss: 0.5987 - val_acc: 0.8702\n",
      "Epoch 754/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 3.9022e-04 - acc: 1.0000 - val_loss: 0.5988 - val_acc: 0.8702\n",
      "Epoch 755/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 3.8909e-04 - acc: 1.0000 - val_loss: 0.5989 - val_acc: 0.8702\n",
      "Epoch 756/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.8791e-04 - acc: 1.0000 - val_loss: 0.5990 - val_acc: 0.8702\n",
      "Epoch 757/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.8676e-04 - acc: 1.0000 - val_loss: 0.5991 - val_acc: 0.8702\n",
      "Epoch 758/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 3.8562e-04 - acc: 1.0000 - val_loss: 0.5992 - val_acc: 0.8702\n",
      "Epoch 759/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 3.8451e-04 - acc: 1.0000 - val_loss: 0.5993 - val_acc: 0.8702\n",
      "Epoch 760/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 3.8336e-04 - acc: 1.0000 - val_loss: 0.5994 - val_acc: 0.8702\n",
      "Epoch 761/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.8221e-04 - acc: 1.0000 - val_loss: 0.5995 - val_acc: 0.8702\n",
      "Epoch 762/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.8112e-04 - acc: 1.0000 - val_loss: 0.5996 - val_acc: 0.8702\n",
      "Epoch 763/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 3.7997e-04 - acc: 1.0000 - val_loss: 0.5997 - val_acc: 0.8702\n",
      "Epoch 764/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.7886e-04 - acc: 1.0000 - val_loss: 0.5998 - val_acc: 0.8702\n",
      "Epoch 765/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.7773e-04 - acc: 1.0000 - val_loss: 0.5999 - val_acc: 0.8702\n",
      "Epoch 766/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.7662e-04 - acc: 1.0000 - val_loss: 0.6000 - val_acc: 0.8702\n",
      "Epoch 767/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.7554e-04 - acc: 1.0000 - val_loss: 0.6001 - val_acc: 0.8702\n",
      "Epoch 768/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.7443e-04 - acc: 1.0000 - val_loss: 0.6002 - val_acc: 0.8702\n",
      "Epoch 769/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.7333e-04 - acc: 1.0000 - val_loss: 0.6003 - val_acc: 0.8702\n",
      "Epoch 770/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 3.7224e-04 - acc: 1.0000 - val_loss: 0.6004 - val_acc: 0.8702\n",
      "Epoch 771/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.7115e-04 - acc: 1.0000 - val_loss: 0.6005 - val_acc: 0.8702\n",
      "Epoch 772/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.7007e-04 - acc: 1.0000 - val_loss: 0.6006 - val_acc: 0.8702\n",
      "Epoch 773/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.6901e-04 - acc: 1.0000 - val_loss: 0.6007 - val_acc: 0.8702\n",
      "Epoch 774/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.6789e-04 - acc: 1.0000 - val_loss: 0.6008 - val_acc: 0.8702\n",
      "Epoch 775/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.6683e-04 - acc: 1.0000 - val_loss: 0.6009 - val_acc: 0.8702\n",
      "Epoch 776/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 3.6578e-04 - acc: 1.0000 - val_loss: 0.6010 - val_acc: 0.8702\n",
      "Epoch 777/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.6472e-04 - acc: 1.0000 - val_loss: 0.6011 - val_acc: 0.8702\n",
      "Epoch 778/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 3.6366e-04 - acc: 1.0000 - val_loss: 0.6012 - val_acc: 0.8702\n",
      "Epoch 779/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.6260e-04 - acc: 1.0000 - val_loss: 0.6013 - val_acc: 0.8702\n",
      "Epoch 780/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.6155e-04 - acc: 1.0000 - val_loss: 0.6014 - val_acc: 0.8702\n",
      "Epoch 781/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.6051e-04 - acc: 1.0000 - val_loss: 0.6015 - val_acc: 0.8702\n",
      "Epoch 782/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.5945e-04 - acc: 1.0000 - val_loss: 0.6016 - val_acc: 0.8702\n",
      "Epoch 783/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.5844e-04 - acc: 1.0000 - val_loss: 0.6017 - val_acc: 0.8702\n",
      "Epoch 784/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.5738e-04 - acc: 1.0000 - val_loss: 0.6018 - val_acc: 0.8702\n",
      "Epoch 785/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.5635e-04 - acc: 1.0000 - val_loss: 0.6019 - val_acc: 0.8702\n",
      "Epoch 786/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.5533e-04 - acc: 1.0000 - val_loss: 0.6020 - val_acc: 0.8702\n",
      "Epoch 787/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.5431e-04 - acc: 1.0000 - val_loss: 0.6021 - val_acc: 0.8702\n",
      "Epoch 788/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.5329e-04 - acc: 1.0000 - val_loss: 0.6022 - val_acc: 0.8702\n",
      "Epoch 789/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.5228e-04 - acc: 1.0000 - val_loss: 0.6023 - val_acc: 0.8702\n",
      "Epoch 790/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 3.5124e-04 - acc: 1.0000 - val_loss: 0.6024 - val_acc: 0.8702\n",
      "Epoch 791/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 3.5023e-04 - acc: 1.0000 - val_loss: 0.6025 - val_acc: 0.8702\n",
      "Epoch 792/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.4925e-04 - acc: 1.0000 - val_loss: 0.6026 - val_acc: 0.8702\n",
      "Epoch 793/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 3.4823e-04 - acc: 1.0000 - val_loss: 0.6027 - val_acc: 0.8702\n",
      "Epoch 794/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 3.4727e-04 - acc: 1.0000 - val_loss: 0.6028 - val_acc: 0.8684\n",
      "Epoch 795/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.4625e-04 - acc: 1.0000 - val_loss: 0.6029 - val_acc: 0.8684\n",
      "Epoch 796/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.4525e-04 - acc: 1.0000 - val_loss: 0.6030 - val_acc: 0.8684\n",
      "Epoch 797/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.4427e-04 - acc: 1.0000 - val_loss: 0.6031 - val_acc: 0.8684\n",
      "Epoch 798/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.4328e-04 - acc: 1.0000 - val_loss: 0.6032 - val_acc: 0.8684\n",
      "Epoch 799/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.4231e-04 - acc: 1.0000 - val_loss: 0.6033 - val_acc: 0.8684\n",
      "Epoch 800/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.4133e-04 - acc: 1.0000 - val_loss: 0.6034 - val_acc: 0.8684\n",
      "Epoch 801/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 3.4037e-04 - acc: 1.0000 - val_loss: 0.6035 - val_acc: 0.8667\n",
      "Epoch 802/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.3940e-04 - acc: 1.0000 - val_loss: 0.6036 - val_acc: 0.8667\n",
      "Epoch 803/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.3844e-04 - acc: 1.0000 - val_loss: 0.6037 - val_acc: 0.8667\n",
      "Epoch 804/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.3747e-04 - acc: 1.0000 - val_loss: 0.6038 - val_acc: 0.8667\n",
      "Epoch 805/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 3.3650e-04 - acc: 1.0000 - val_loss: 0.6039 - val_acc: 0.8667\n",
      "Epoch 806/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.3555e-04 - acc: 1.0000 - val_loss: 0.6040 - val_acc: 0.8667\n",
      "Epoch 807/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 3.3462e-04 - acc: 1.0000 - val_loss: 0.6041 - val_acc: 0.8667\n",
      "Epoch 808/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.3367e-04 - acc: 1.0000 - val_loss: 0.6042 - val_acc: 0.8667\n",
      "Epoch 809/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 20us/sample - loss: 3.3274e-04 - acc: 1.0000 - val_loss: 0.6043 - val_acc: 0.8667\n",
      "Epoch 810/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.3179e-04 - acc: 1.0000 - val_loss: 0.6044 - val_acc: 0.8667\n",
      "Epoch 811/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 3.3086e-04 - acc: 1.0000 - val_loss: 0.6045 - val_acc: 0.8667\n",
      "Epoch 812/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 3.2990e-04 - acc: 1.0000 - val_loss: 0.6046 - val_acc: 0.8667\n",
      "Epoch 813/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.2898e-04 - acc: 1.0000 - val_loss: 0.6047 - val_acc: 0.8667\n",
      "Epoch 814/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.2806e-04 - acc: 1.0000 - val_loss: 0.6048 - val_acc: 0.8667\n",
      "Epoch 815/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 3.2714e-04 - acc: 1.0000 - val_loss: 0.6048 - val_acc: 0.8667\n",
      "Epoch 816/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.2621e-04 - acc: 1.0000 - val_loss: 0.6049 - val_acc: 0.8667\n",
      "Epoch 817/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 3.2530e-04 - acc: 1.0000 - val_loss: 0.6050 - val_acc: 0.8667\n",
      "Epoch 818/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.2439e-04 - acc: 1.0000 - val_loss: 0.6051 - val_acc: 0.8667\n",
      "Epoch 819/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.2350e-04 - acc: 1.0000 - val_loss: 0.6052 - val_acc: 0.8667\n",
      "Epoch 820/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.2258e-04 - acc: 1.0000 - val_loss: 0.6053 - val_acc: 0.8667\n",
      "Epoch 821/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.2167e-04 - acc: 1.0000 - val_loss: 0.6054 - val_acc: 0.8667\n",
      "Epoch 822/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 3.2078e-04 - acc: 1.0000 - val_loss: 0.6055 - val_acc: 0.8667\n",
      "Epoch 823/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 3.1990e-04 - acc: 1.0000 - val_loss: 0.6056 - val_acc: 0.8667\n",
      "Epoch 824/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 3.1899e-04 - acc: 1.0000 - val_loss: 0.6057 - val_acc: 0.8667\n",
      "Epoch 825/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.1810e-04 - acc: 1.0000 - val_loss: 0.6058 - val_acc: 0.8667\n",
      "Epoch 826/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.1722e-04 - acc: 1.0000 - val_loss: 0.6059 - val_acc: 0.8667\n",
      "Epoch 827/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.1635e-04 - acc: 1.0000 - val_loss: 0.6060 - val_acc: 0.8667\n",
      "Epoch 828/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.1545e-04 - acc: 1.0000 - val_loss: 0.6061 - val_acc: 0.8667\n",
      "Epoch 829/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.1459e-04 - acc: 1.0000 - val_loss: 0.6062 - val_acc: 0.8667\n",
      "Epoch 830/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.1371e-04 - acc: 1.0000 - val_loss: 0.6063 - val_acc: 0.8667\n",
      "Epoch 831/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.1285e-04 - acc: 1.0000 - val_loss: 0.6064 - val_acc: 0.8667\n",
      "Epoch 832/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.1196e-04 - acc: 1.0000 - val_loss: 0.6065 - val_acc: 0.8667\n",
      "Epoch 833/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.1112e-04 - acc: 1.0000 - val_loss: 0.6066 - val_acc: 0.8667\n",
      "Epoch 834/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.1024e-04 - acc: 1.0000 - val_loss: 0.6067 - val_acc: 0.8667\n",
      "Epoch 835/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.0939e-04 - acc: 1.0000 - val_loss: 0.6068 - val_acc: 0.8667\n",
      "Epoch 836/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.0855e-04 - acc: 1.0000 - val_loss: 0.6069 - val_acc: 0.8667\n",
      "Epoch 837/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.0770e-04 - acc: 1.0000 - val_loss: 0.6070 - val_acc: 0.8667\n",
      "Epoch 838/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 3.0683e-04 - acc: 1.0000 - val_loss: 0.6071 - val_acc: 0.8667\n",
      "Epoch 839/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.0600e-04 - acc: 1.0000 - val_loss: 0.6072 - val_acc: 0.8667\n",
      "Epoch 840/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.0517e-04 - acc: 1.0000 - val_loss: 0.6073 - val_acc: 0.8667\n",
      "Epoch 841/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 3.0431e-04 - acc: 1.0000 - val_loss: 0.6073 - val_acc: 0.8667\n",
      "Epoch 842/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.0349e-04 - acc: 1.0000 - val_loss: 0.6074 - val_acc: 0.8667\n",
      "Epoch 843/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 3.0266e-04 - acc: 1.0000 - val_loss: 0.6075 - val_acc: 0.8667\n",
      "Epoch 844/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 3.0181e-04 - acc: 1.0000 - val_loss: 0.6076 - val_acc: 0.8667\n",
      "Epoch 845/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 3.0101e-04 - acc: 1.0000 - val_loss: 0.6077 - val_acc: 0.8667\n",
      "Epoch 846/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 3.0018e-04 - acc: 1.0000 - val_loss: 0.6078 - val_acc: 0.8667\n",
      "Epoch 847/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.9934e-04 - acc: 1.0000 - val_loss: 0.6079 - val_acc: 0.8667\n",
      "Epoch 848/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.9853e-04 - acc: 1.0000 - val_loss: 0.6080 - val_acc: 0.8667\n",
      "Epoch 849/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.9771e-04 - acc: 1.0000 - val_loss: 0.6081 - val_acc: 0.8667\n",
      "Epoch 850/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.9691e-04 - acc: 1.0000 - val_loss: 0.6082 - val_acc: 0.8667\n",
      "Epoch 851/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.9612e-04 - acc: 1.0000 - val_loss: 0.6083 - val_acc: 0.8667\n",
      "Epoch 852/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.9530e-04 - acc: 1.0000 - val_loss: 0.6084 - val_acc: 0.8667\n",
      "Epoch 853/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.9450e-04 - acc: 1.0000 - val_loss: 0.6085 - val_acc: 0.8667\n",
      "Epoch 854/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.9371e-04 - acc: 1.0000 - val_loss: 0.6086 - val_acc: 0.8667\n",
      "Epoch 855/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.9289e-04 - acc: 1.0000 - val_loss: 0.6087 - val_acc: 0.8667\n",
      "Epoch 856/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.9211e-04 - acc: 1.0000 - val_loss: 0.6088 - val_acc: 0.8667\n",
      "Epoch 857/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.9130e-04 - acc: 1.0000 - val_loss: 0.6089 - val_acc: 0.8667\n",
      "Epoch 858/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 2.9052e-04 - acc: 1.0000 - val_loss: 0.6090 - val_acc: 0.8667\n",
      "Epoch 859/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.8976e-04 - acc: 1.0000 - val_loss: 0.6091 - val_acc: 0.8667\n",
      "Epoch 860/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.8897e-04 - acc: 1.0000 - val_loss: 0.6092 - val_acc: 0.8667\n",
      "Epoch 861/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.8818e-04 - acc: 1.0000 - val_loss: 0.6093 - val_acc: 0.8667\n",
      "Epoch 862/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.8739e-04 - acc: 1.0000 - val_loss: 0.6094 - val_acc: 0.8667\n",
      "Epoch 863/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.8662e-04 - acc: 1.0000 - val_loss: 0.6095 - val_acc: 0.8667\n",
      "Epoch 864/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.8585e-04 - acc: 1.0000 - val_loss: 0.6096 - val_acc: 0.8667\n",
      "Epoch 865/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.8507e-04 - acc: 1.0000 - val_loss: 0.6097 - val_acc: 0.8667\n",
      "Epoch 866/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 20us/sample - loss: 2.8430e-04 - acc: 1.0000 - val_loss: 0.6098 - val_acc: 0.8667\n",
      "Epoch 867/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 2.8353e-04 - acc: 1.0000 - val_loss: 0.6099 - val_acc: 0.8667\n",
      "Epoch 868/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.8277e-04 - acc: 1.0000 - val_loss: 0.6100 - val_acc: 0.8667\n",
      "Epoch 869/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.8202e-04 - acc: 1.0000 - val_loss: 0.6101 - val_acc: 0.8667\n",
      "Epoch 870/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.8126e-04 - acc: 1.0000 - val_loss: 0.6102 - val_acc: 0.8667\n",
      "Epoch 871/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.8049e-04 - acc: 1.0000 - val_loss: 0.6103 - val_acc: 0.8684\n",
      "Epoch 872/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.7976e-04 - acc: 1.0000 - val_loss: 0.6104 - val_acc: 0.8684\n",
      "Epoch 873/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.7900e-04 - acc: 1.0000 - val_loss: 0.6105 - val_acc: 0.8684\n",
      "Epoch 874/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.7827e-04 - acc: 1.0000 - val_loss: 0.6105 - val_acc: 0.8684\n",
      "Epoch 875/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.7750e-04 - acc: 1.0000 - val_loss: 0.6106 - val_acc: 0.8684\n",
      "Epoch 876/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.7675e-04 - acc: 1.0000 - val_loss: 0.6107 - val_acc: 0.8684\n",
      "Epoch 877/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.7603e-04 - acc: 1.0000 - val_loss: 0.6108 - val_acc: 0.8684\n",
      "Epoch 878/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 2.7529e-04 - acc: 1.0000 - val_loss: 0.6109 - val_acc: 0.8684\n",
      "Epoch 879/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.7455e-04 - acc: 1.0000 - val_loss: 0.6110 - val_acc: 0.8684\n",
      "Epoch 880/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.7382e-04 - acc: 1.0000 - val_loss: 0.6111 - val_acc: 0.8684\n",
      "Epoch 881/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.7309e-04 - acc: 1.0000 - val_loss: 0.6112 - val_acc: 0.8684\n",
      "Epoch 882/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.7237e-04 - acc: 1.0000 - val_loss: 0.6113 - val_acc: 0.8684\n",
      "Epoch 883/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.7165e-04 - acc: 1.0000 - val_loss: 0.6114 - val_acc: 0.8684\n",
      "Epoch 884/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.7091e-04 - acc: 1.0000 - val_loss: 0.6115 - val_acc: 0.8684\n",
      "Epoch 885/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.7020e-04 - acc: 1.0000 - val_loss: 0.6116 - val_acc: 0.8684\n",
      "Epoch 886/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.6948e-04 - acc: 1.0000 - val_loss: 0.6117 - val_acc: 0.8684\n",
      "Epoch 887/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.6878e-04 - acc: 1.0000 - val_loss: 0.6118 - val_acc: 0.8684\n",
      "Epoch 888/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.6806e-04 - acc: 1.0000 - val_loss: 0.6119 - val_acc: 0.8684\n",
      "Epoch 889/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.6735e-04 - acc: 1.0000 - val_loss: 0.6120 - val_acc: 0.8684\n",
      "Epoch 890/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.6664e-04 - acc: 1.0000 - val_loss: 0.6121 - val_acc: 0.8684\n",
      "Epoch 891/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.6594e-04 - acc: 1.0000 - val_loss: 0.6122 - val_acc: 0.8684\n",
      "Epoch 892/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.6523e-04 - acc: 1.0000 - val_loss: 0.6122 - val_acc: 0.8684\n",
      "Epoch 893/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.6453e-04 - acc: 1.0000 - val_loss: 0.6123 - val_acc: 0.8684\n",
      "Epoch 894/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.6384e-04 - acc: 1.0000 - val_loss: 0.6124 - val_acc: 0.8684\n",
      "Epoch 895/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.6315e-04 - acc: 1.0000 - val_loss: 0.6125 - val_acc: 0.8684\n",
      "Epoch 896/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.6245e-04 - acc: 1.0000 - val_loss: 0.6126 - val_acc: 0.8684\n",
      "Epoch 897/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.6176e-04 - acc: 1.0000 - val_loss: 0.6127 - val_acc: 0.8684\n",
      "Epoch 898/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.6107e-04 - acc: 1.0000 - val_loss: 0.6128 - val_acc: 0.8684\n",
      "Epoch 899/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.6039e-04 - acc: 1.0000 - val_loss: 0.6129 - val_acc: 0.8684\n",
      "Epoch 900/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.5970e-04 - acc: 1.0000 - val_loss: 0.6130 - val_acc: 0.8684\n",
      "Epoch 901/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.5903e-04 - acc: 1.0000 - val_loss: 0.6131 - val_acc: 0.8684\n",
      "Epoch 902/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.5834e-04 - acc: 1.0000 - val_loss: 0.6132 - val_acc: 0.8684\n",
      "Epoch 903/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.5767e-04 - acc: 1.0000 - val_loss: 0.6133 - val_acc: 0.8684\n",
      "Epoch 904/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.5698e-04 - acc: 1.0000 - val_loss: 0.6134 - val_acc: 0.8684\n",
      "Epoch 905/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.5633e-04 - acc: 1.0000 - val_loss: 0.6135 - val_acc: 0.8684\n",
      "Epoch 906/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.5566e-04 - acc: 1.0000 - val_loss: 0.6136 - val_acc: 0.8684\n",
      "Epoch 907/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.5498e-04 - acc: 1.0000 - val_loss: 0.6136 - val_acc: 0.8684\n",
      "Epoch 908/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.5432e-04 - acc: 1.0000 - val_loss: 0.6137 - val_acc: 0.8684\n",
      "Epoch 909/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.5365e-04 - acc: 1.0000 - val_loss: 0.6138 - val_acc: 0.8684\n",
      "Epoch 910/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.5300e-04 - acc: 1.0000 - val_loss: 0.6139 - val_acc: 0.8684\n",
      "Epoch 911/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.5235e-04 - acc: 1.0000 - val_loss: 0.6140 - val_acc: 0.8684\n",
      "Epoch 912/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.5169e-04 - acc: 1.0000 - val_loss: 0.6141 - val_acc: 0.8684\n",
      "Epoch 913/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.5102e-04 - acc: 1.0000 - val_loss: 0.6142 - val_acc: 0.8684\n",
      "Epoch 914/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.5039e-04 - acc: 1.0000 - val_loss: 0.6143 - val_acc: 0.8684\n",
      "Epoch 915/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.4973e-04 - acc: 1.0000 - val_loss: 0.6144 - val_acc: 0.8684\n",
      "Epoch 916/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.4908e-04 - acc: 1.0000 - val_loss: 0.6145 - val_acc: 0.8684\n",
      "Epoch 917/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.4844e-04 - acc: 1.0000 - val_loss: 0.6146 - val_acc: 0.8684\n",
      "Epoch 918/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.4780e-04 - acc: 1.0000 - val_loss: 0.6147 - val_acc: 0.8684\n",
      "Epoch 919/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.4717e-04 - acc: 1.0000 - val_loss: 0.6148 - val_acc: 0.8684\n",
      "Epoch 920/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.4652e-04 - acc: 1.0000 - val_loss: 0.6149 - val_acc: 0.8684\n",
      "Epoch 921/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.4588e-04 - acc: 1.0000 - val_loss: 0.6149 - val_acc: 0.8684\n",
      "Epoch 922/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.4525e-04 - acc: 1.0000 - val_loss: 0.6150 - val_acc: 0.8684\n",
      "Epoch 923/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 21us/sample - loss: 2.4462e-04 - acc: 1.0000 - val_loss: 0.6151 - val_acc: 0.8684\n",
      "Epoch 924/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.4400e-04 - acc: 1.0000 - val_loss: 0.6152 - val_acc: 0.8684\n",
      "Epoch 925/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.4336e-04 - acc: 1.0000 - val_loss: 0.6153 - val_acc: 0.8684\n",
      "Epoch 926/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 2.4273e-04 - acc: 1.0000 - val_loss: 0.6154 - val_acc: 0.8684\n",
      "Epoch 927/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.4211e-04 - acc: 1.0000 - val_loss: 0.6155 - val_acc: 0.8684\n",
      "Epoch 928/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.4149e-04 - acc: 1.0000 - val_loss: 0.6156 - val_acc: 0.8684\n",
      "Epoch 929/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.4088e-04 - acc: 1.0000 - val_loss: 0.6157 - val_acc: 0.8684\n",
      "Epoch 930/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.4025e-04 - acc: 1.0000 - val_loss: 0.6158 - val_acc: 0.8684\n",
      "Epoch 931/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.3964e-04 - acc: 1.0000 - val_loss: 0.6159 - val_acc: 0.8684\n",
      "Epoch 932/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.3902e-04 - acc: 1.0000 - val_loss: 0.6160 - val_acc: 0.8684\n",
      "Epoch 933/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.3841e-04 - acc: 1.0000 - val_loss: 0.6160 - val_acc: 0.8684\n",
      "Epoch 934/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.3779e-04 - acc: 1.0000 - val_loss: 0.6161 - val_acc: 0.8684\n",
      "Epoch 935/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.3719e-04 - acc: 1.0000 - val_loss: 0.6162 - val_acc: 0.8684\n",
      "Epoch 936/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.3659e-04 - acc: 1.0000 - val_loss: 0.6163 - val_acc: 0.8684\n",
      "Epoch 937/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.3598e-04 - acc: 1.0000 - val_loss: 0.6164 - val_acc: 0.8684\n",
      "Epoch 938/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.3536e-04 - acc: 1.0000 - val_loss: 0.6165 - val_acc: 0.8684\n",
      "Epoch 939/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.3477e-04 - acc: 1.0000 - val_loss: 0.6166 - val_acc: 0.8684\n",
      "Epoch 940/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.3419e-04 - acc: 1.0000 - val_loss: 0.6167 - val_acc: 0.8684\n",
      "Epoch 941/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.3359e-04 - acc: 1.0000 - val_loss: 0.6168 - val_acc: 0.8684\n",
      "Epoch 942/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.3299e-04 - acc: 1.0000 - val_loss: 0.6169 - val_acc: 0.8684\n",
      "Epoch 943/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.3240e-04 - acc: 1.0000 - val_loss: 0.6170 - val_acc: 0.8684\n",
      "Epoch 944/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.3181e-04 - acc: 1.0000 - val_loss: 0.6171 - val_acc: 0.8684\n",
      "Epoch 945/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.3123e-04 - acc: 1.0000 - val_loss: 0.6172 - val_acc: 0.8684\n",
      "Epoch 946/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.3063e-04 - acc: 1.0000 - val_loss: 0.6172 - val_acc: 0.8684\n",
      "Epoch 947/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.3004e-04 - acc: 1.0000 - val_loss: 0.6173 - val_acc: 0.8684\n",
      "Epoch 948/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.2946e-04 - acc: 1.0000 - val_loss: 0.6174 - val_acc: 0.8684\n",
      "Epoch 949/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.2889e-04 - acc: 1.0000 - val_loss: 0.6175 - val_acc: 0.8684\n",
      "Epoch 950/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.2831e-04 - acc: 1.0000 - val_loss: 0.6176 - val_acc: 0.8684\n",
      "Epoch 951/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.2774e-04 - acc: 1.0000 - val_loss: 0.6177 - val_acc: 0.8684\n",
      "Epoch 952/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.2716e-04 - acc: 1.0000 - val_loss: 0.6178 - val_acc: 0.8684\n",
      "Epoch 953/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.2660e-04 - acc: 1.0000 - val_loss: 0.6179 - val_acc: 0.8684\n",
      "Epoch 954/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.2600e-04 - acc: 1.0000 - val_loss: 0.6180 - val_acc: 0.8684\n",
      "Epoch 955/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.2544e-04 - acc: 1.0000 - val_loss: 0.6181 - val_acc: 0.8684\n",
      "Epoch 956/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.2487e-04 - acc: 1.0000 - val_loss: 0.6181 - val_acc: 0.8684\n",
      "Epoch 957/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.2431e-04 - acc: 1.0000 - val_loss: 0.6182 - val_acc: 0.8684\n",
      "Epoch 958/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.2375e-04 - acc: 1.0000 - val_loss: 0.6183 - val_acc: 0.8684\n",
      "Epoch 959/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.2318e-04 - acc: 1.0000 - val_loss: 0.6184 - val_acc: 0.8684\n",
      "Epoch 960/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.2262e-04 - acc: 1.0000 - val_loss: 0.6185 - val_acc: 0.8684\n",
      "Epoch 961/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.2207e-04 - acc: 1.0000 - val_loss: 0.6186 - val_acc: 0.8684\n",
      "Epoch 962/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.2152e-04 - acc: 1.0000 - val_loss: 0.6187 - val_acc: 0.8684\n",
      "Epoch 963/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 2.2095e-04 - acc: 1.0000 - val_loss: 0.6188 - val_acc: 0.8684\n",
      "Epoch 964/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.2039e-04 - acc: 1.0000 - val_loss: 0.6189 - val_acc: 0.8684\n",
      "Epoch 965/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.1985e-04 - acc: 1.0000 - val_loss: 0.6190 - val_acc: 0.8684\n",
      "Epoch 966/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.1929e-04 - acc: 1.0000 - val_loss: 0.6191 - val_acc: 0.8684\n",
      "Epoch 967/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.1874e-04 - acc: 1.0000 - val_loss: 0.6191 - val_acc: 0.8684\n",
      "Epoch 968/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.1821e-04 - acc: 1.0000 - val_loss: 0.6192 - val_acc: 0.8684\n",
      "Epoch 969/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.1766e-04 - acc: 1.0000 - val_loss: 0.6193 - val_acc: 0.8684\n",
      "Epoch 970/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.1711e-04 - acc: 1.0000 - val_loss: 0.6194 - val_acc: 0.8684\n",
      "Epoch 971/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.1657e-04 - acc: 1.0000 - val_loss: 0.6195 - val_acc: 0.8684\n",
      "Epoch 972/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.1604e-04 - acc: 1.0000 - val_loss: 0.6196 - val_acc: 0.8684\n",
      "Epoch 973/1000\n",
      "570/570 [==============================] - 0s 18us/sample - loss: 2.1549e-04 - acc: 1.0000 - val_loss: 0.6197 - val_acc: 0.8684\n",
      "Epoch 974/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.1496e-04 - acc: 1.0000 - val_loss: 0.6198 - val_acc: 0.8684\n",
      "Epoch 975/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.1442e-04 - acc: 1.0000 - val_loss: 0.6199 - val_acc: 0.8684\n",
      "Epoch 976/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.1388e-04 - acc: 1.0000 - val_loss: 0.6200 - val_acc: 0.8684\n",
      "Epoch 977/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.1335e-04 - acc: 1.0000 - val_loss: 0.6201 - val_acc: 0.8684\n",
      "Epoch 978/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.1283e-04 - acc: 1.0000 - val_loss: 0.6201 - val_acc: 0.8684\n",
      "Epoch 979/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.1231e-04 - acc: 1.0000 - val_loss: 0.6202 - val_acc: 0.8684\n",
      "Epoch 980/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 18us/sample - loss: 2.1177e-04 - acc: 1.0000 - val_loss: 0.6203 - val_acc: 0.8684\n",
      "Epoch 981/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.1125e-04 - acc: 1.0000 - val_loss: 0.6204 - val_acc: 0.8684\n",
      "Epoch 982/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.1071e-04 - acc: 1.0000 - val_loss: 0.6205 - val_acc: 0.8684\n",
      "Epoch 983/1000\n",
      "570/570 [==============================] - 0s 23us/sample - loss: 2.1019e-04 - acc: 1.0000 - val_loss: 0.6206 - val_acc: 0.8684\n",
      "Epoch 984/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.0969e-04 - acc: 1.0000 - val_loss: 0.6207 - val_acc: 0.8684\n",
      "Epoch 985/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.0916e-04 - acc: 1.0000 - val_loss: 0.6208 - val_acc: 0.8684\n",
      "Epoch 986/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.0864e-04 - acc: 1.0000 - val_loss: 0.6209 - val_acc: 0.8684\n",
      "Epoch 987/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.0812e-04 - acc: 1.0000 - val_loss: 0.6210 - val_acc: 0.8684\n",
      "Epoch 988/1000\n",
      "570/570 [==============================] - 0s 19us/sample - loss: 2.0761e-04 - acc: 1.0000 - val_loss: 0.6211 - val_acc: 0.8684\n",
      "Epoch 989/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.0710e-04 - acc: 1.0000 - val_loss: 0.6211 - val_acc: 0.8684\n",
      "Epoch 990/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.0659e-04 - acc: 1.0000 - val_loss: 0.6212 - val_acc: 0.8684\n",
      "Epoch 991/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.0608e-04 - acc: 1.0000 - val_loss: 0.6213 - val_acc: 0.8684\n",
      "Epoch 992/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.0558e-04 - acc: 1.0000 - val_loss: 0.6214 - val_acc: 0.8684\n",
      "Epoch 993/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.0506e-04 - acc: 1.0000 - val_loss: 0.6215 - val_acc: 0.8684\n",
      "Epoch 994/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.0456e-04 - acc: 1.0000 - val_loss: 0.6216 - val_acc: 0.8684\n",
      "Epoch 995/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.0406e-04 - acc: 1.0000 - val_loss: 0.6217 - val_acc: 0.8684\n",
      "Epoch 996/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.0356e-04 - acc: 1.0000 - val_loss: 0.6218 - val_acc: 0.8684\n",
      "Epoch 997/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.0307e-04 - acc: 1.0000 - val_loss: 0.6219 - val_acc: 0.8684\n",
      "Epoch 998/1000\n",
      "570/570 [==============================] - 0s 22us/sample - loss: 2.0257e-04 - acc: 1.0000 - val_loss: 0.6219 - val_acc: 0.8684\n",
      "Epoch 999/1000\n",
      "570/570 [==============================] - 0s 20us/sample - loss: 2.0207e-04 - acc: 1.0000 - val_loss: 0.6220 - val_acc: 0.8684\n",
      "Epoch 1000/1000\n",
      "570/570 [==============================] - 0s 21us/sample - loss: 2.0157e-04 - acc: 1.0000 - val_loss: 0.6221 - val_acc: 0.8684\n"
     ]
    }
   ],
   "source": [
    "# TO DO\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "nnode = 100\n",
    "lr = 1e-3\n",
    "nepochs = 1000\n",
    "batch_size = 200\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Dense(nnode, activation = 'relu', input_shape=Xtr_pca.shape[1:]))\n",
    "model.add(Dense(n_classes, activation = 'softmax'))\n",
    "opt = optimizers.Adam(lr=lr)\n",
    "hist = model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "print(model.summary()) \n",
    "hist = model.fit(Xtr_pca, y_train, batch_size=batch_size,\n",
    "              epochs=nepochs, validation_data=(Xts_pca, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochsn=np.arange(1, nepochs+1)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochsn, hist.history['loss'], label='Loss')\n",
    "plt.plot(epochsn, hist.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochsn, hist.history['acc'], label='Accuracy')\n",
    "plt.plot(epochsn, hist.history['val_acc'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to identify the best number of PCs and the best number of hidden nodes in the NN classifer that can achieve the highest validation accuracy. \n",
    "You can set the range of PCs and nubmer of hidden nodes as below.\n",
    "\n",
    "nnodes = [50,100,150,200, 250],\n",
    "npcs = [50,100,150,200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an array to store accuracy for different nnode and npcs\n",
    "# TO DO\n",
    "nnodes = [50,100,150,200,250]\n",
    "npcs = [50,100,150,200]\n",
    "hist_value = np.zeros((4,len(nnodes),len(npcs),nepochs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 2,805\n",
      "Trainable params: 2,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 5,305\n",
      "Trainable params: 5,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                7550      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 7,805\n",
      "Trainable params: 7,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 10,305\n",
      "Trainable params: 10,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 5,605\n",
      "Trainable params: 5,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 10,605\n",
      "Trainable params: 10,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 15,605\n",
      "Trainable params: 15,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 20,605\n",
      "Trainable params: 20,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 150)               7650      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 755       \n",
      "=================================================================\n",
      "Total params: 8,405\n",
      "Trainable params: 8,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 150)               15150     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 755       \n",
      "=================================================================\n",
      "Total params: 15,905\n",
      "Trainable params: 15,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 755       \n",
      "=================================================================\n",
      "Total params: 23,405\n",
      "Trainable params: 23,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 755       \n",
      "=================================================================\n",
      "Total params: 30,905\n",
      "Trainable params: 30,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               10200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 11,205\n",
      "Trainable params: 11,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 21,205\n",
      "Trainable params: 21,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               30200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 31,205\n",
      "Trainable params: 31,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 41,205\n",
      "Trainable params: 41,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 250)               12750     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 14,005\n",
      "Trainable params: 14,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 250)               25250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 26,505\n",
      "Trainable params: 26,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 250)               37750     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 39,005\n",
      "Trainable params: 39,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 51,505\n",
      "Trainable params: 51,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Loop through the combinations to find the accuracy for each combination\n",
    "# For each possible combination of `nnode` and `npc`, set up and fit the model \n",
    "# using features containing only coefficents corresponding to npc coefficients.\n",
    "\n",
    "# TO DO \n",
    "for i, node in enumerate(nnodes):\n",
    "    for j, pcs in enumerate(npcs):\n",
    "        # PCA\n",
    "        pca = PCA(n_components=pcs, svd_solver='randomized', whiten=True).fit(Xtr)\n",
    "        Xtr_pca = pca.transform(Xtr)\n",
    "        Xts_pca = pca.transform(Xts)\n",
    "        # NN\n",
    "        K.clear_session()\n",
    "        model = Sequential()\n",
    "        model.add(Dense(node, activation = 'relu', input_shape=Xtr_pca.shape[1:]))\n",
    "        model.add(Dense(n_classes, activation = 'softmax'))\n",
    "        opt = optimizers.Adam(lr=lr)\n",
    "        hist = model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "        print(model.summary()) \n",
    "        hist = model.fit(Xtr_pca, y_train, batch_size=batch_size,\n",
    "              epochs=nepochs, validation_data=(Xts_pca, y_test),\n",
    "              shuffle=False, verbose=0)\n",
    "        hist_value[0,i,j,:] = hist.history['loss']\n",
    "        hist_value[1,i,j,:] = hist.history['val_loss']\n",
    "        hist_value[2,i,j,:] = hist.history['acc']\n",
    "        hist_value[3,i,j,:] = hist.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal nnode =  150\n",
      "Optimal npc =  100\n"
     ]
    }
   ],
   "source": [
    "# Determine the npc and nnode that provides the highest validation accuracy \n",
    "# TO DO \n",
    "tmp = np.mean(hist_value[3,:,:,-10:],axis=2)\n",
    "tmp = np.argmax(tmp)\n",
    "n1 = tmp//len(npcs)\n",
    "n2 = tmp%len(npcs)\n",
    "opt_node = nnodes[n1]\n",
    "opt_npc = npcs[n2]\n",
    "print('Optimal nnode = ', opt_node)\n",
    "print('Optimal npc = ', opt_npc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Produce a contour plot of the accuracy using different nnode and npc combincations\n",
    "# TO DO\n",
    "# epochsn=np.arange(1, nepochs+1)\n",
    "# plt.figure(figsize=(10,10))\n",
    "# for i in range(len(nnodes)):\n",
    "#     for j in range(len(npcs)):\n",
    "#         plt.subplot(2,2,1)\n",
    "#         plt.plot(epochsn, hist_value[0,i,j,:], label='Num of Nodes = '+ np.str(i) + ', Num of PC = ' + np.str(j))\n",
    "#         plt.subplot(2,2,2)\n",
    "#         plt.plot(epochsn, hist_value[1,i,j,:], label='Num of Nodes = '+ np.str(i) + ', Num of PC = ' + np.str(j))\n",
    "#         plt.subplot(2,2,3)\n",
    "#         plt.plot(epochsn, hist_value[2,i,j,:], label='Num of Nodes = '+ np.str(i) + ', Num of PC = ' + np.str(j))\n",
    "#         plt.subplot(2,2,4)\n",
    "#         plt.plot(epochsn, hist_value[3,i,j,:], label='Num of Nodes = '+ np.str(i) + ', Num of PC = ' + np.str(j))\n",
    "# plt.subplot(2,2,1)\n",
    "# plt.title('Loss')\n",
    "# plt.xlabel('epoch')\n",
    "# # plt.legend()\n",
    "# plt.grid()\n",
    "# plt.subplot(2,2,2)\n",
    "# plt.title('Validation Loss')\n",
    "# plt.xlabel('epoch')\n",
    "# # plt.legend()\n",
    "# plt.grid()\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.title('Accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# # plt.legend()\n",
    "# plt.grid()\n",
    "# plt.subplot(2,2,4)\n",
    "# plt.title('Validation Accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# # plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "# plt.contourf ...\n",
    "tmp = np.mean(hist_value[3,:,:,-10:],axis=2)\n",
    "NN, NP = np.meshgrid(npcs, nnodes)\n",
    "plt.figure()\n",
    "# tmp = np.reshape(hist_value[3,:,:,:],(4*5,nepochs))\n",
    "plt.contourf(NN, NP, tmp)\n",
    "plt.xlabel('Number of Nodes')\n",
    "plt.ylabel('Number of PCs')\n",
    "plt.grid()\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let us compare the PCA+NN with applying a CNN on the raw image data only. \n",
    "\n",
    "Note that you should scale your image data to between 0 and 1. And you should reshape your training and testing data according to image width and height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation for input to CNN\n",
    "# TO DO\n",
    "Xtr = np.reshape(X_train.astype('float32') / 255., (X_train.shape[0],h,w,1))\n",
    "Xts = np.reshape(X_test.astype('float32') / 255., (X_test.shape[0],h,w,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 46, 33, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 23, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 19, 12, 16)        6416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 864)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               173000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 180,837\n",
      "Trainable params: 180,837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up a CNN model\n",
    "# You can use 2 conv2D layer, each with kernel size of 5x5, each followed by a pooling layer with strides of 2\n",
    "# For this part, let both conv2D layer generate 16 channels. \n",
    "# The Conv layer should be followed by a flatten layer and two dense layers. \n",
    "# The first dense layer should produce 200 outputs. \n",
    "# The last dense layer is the output layer with n_classes output using 'softmax' activation.\n",
    "# Print model summary to verify it follows the desired structure and compile the model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# TO DO \n",
    "def create_mod(input_shape, n_classes, hid_ch):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(hid_ch, (5, 5), padding='valid', activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(hid_ch, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200, activation = 'relu'))\n",
    "    model.add(Dense(n_classes, activation = 'softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# NN\n",
    "K.clear_session()\n",
    "model = create_mod(Xtr.shape[1:], n_classes, 16)\n",
    "model.summary()\n",
    "opt = optimizers.Adam(lr=lr)\n",
    "hist = model.compile(loss='sparse_categorical_crossentropy',\n",
    "          optimizer=opt,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model using batch size=100, epochs = 40\n",
    "# Print the accuracy on the validation set\n",
    "\n",
    "# TO DO \n",
    "batch_size = 100\n",
    "# nepochs = 4\n",
    "hist = model.fit(Xtr, y_train, batch_size=batch_size,\n",
    "      epochs=nepochs, validation_data=(Xts, y_test),\n",
    "      shuffle=False, verbose=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(nepochs), hist.history['val_acc'], label='CNN')\n",
    "plt.plot(np.arange(nepochs), hist_value[3,n1,n2,:], label='PCA+NN')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "How do the result compared with the PCA+NN method? (If you did right, they should be similar, with PCA+NN being slightly better. If you used more training data (e.g. 75%) and you trained the CNN with more epochs, CNN method may get better). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat the above using a small dataset\n",
    "\n",
    "Instead of using 50% of the total data for training, let us assume you have only 10% of the total data for training. Repeat both the PCA+NN and the CNN method, to see which one gives you better results. \n",
    "\n",
    "Note that with only 10% data for training, the range of the npc has to be set to be below the total number of training samples. \n",
    "\n",
    "For the CNN model, because you have small number of training samples, you cannot train a network with a large number of parameters reliably. Instead of producing 16 channels for each of the two conv2D layers, configure the model to produce only 8 channels each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 1850)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 2,805\n",
      "Trainable params: 2,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 5,305\n",
      "Trainable params: 5,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 5,605\n",
      "Trainable params: 5,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 10,605\n",
      "Trainable params: 10,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 150)               7650      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 755       \n",
      "=================================================================\n",
      "Total params: 8,405\n",
      "Trainable params: 8,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 150)               15150     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 755       \n",
      "=================================================================\n",
      "Total params: 15,905\n",
      "Trainable params: 15,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               10200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 11,205\n",
      "Trainable params: 11,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 21,205\n",
      "Trainable params: 21,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 250)               12750     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 14,005\n",
      "Trainable params: 14,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 250)               25250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 26,505\n",
      "Trainable params: 26,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Optimal nnode =  200\n",
      "Optimal npc =  50\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TO DO\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, stratify=y, random_state=43)\n",
    "print(X_train.shape)\n",
    "# Perfom PCA\n",
    "npc = 100\n",
    "n_samples, _ = X_train.shape\n",
    "Xtr_mean = np.mean(X_train,0)\n",
    "Xtr = X_train - Xtr_mean[None,:]\n",
    "Xts_mean = np.mean(X_test,0)\n",
    "Xts = X_test - Xts_mean[None,:]\n",
    "pca = PCA(n_components=npc, svd_solver='randomized', whiten=True).fit(Xtr)\n",
    "# TO DO\n",
    "Xtr_pca = pca.transform(Xtr)\n",
    "Xts_pca = pca.transform(Xts)\n",
    "# Loop through the combinations to find the accuracy for each combination\n",
    "nnodes = [50,100,150,200,250]\n",
    "npcs = [50,100]\n",
    "hist_value = np.zeros((4,len(nnodes),len(npcs),nepochs))\n",
    "for i, node in enumerate(nnodes):\n",
    "    for j, pcs in enumerate(npcs):\n",
    "        # PCA\n",
    "        pca = PCA(n_components=pcs, svd_solver='randomized', whiten=True).fit(Xtr)\n",
    "        Xtr_pca = pca.transform(Xtr)\n",
    "        Xts_pca = pca.transform(Xts)\n",
    "        # NN\n",
    "        K.clear_session()\n",
    "        model = Sequential()\n",
    "        model.add(Dense(node, activation = 'relu', input_shape=Xtr_pca.shape[1:]))\n",
    "        model.add(Dense(n_classes, activation = 'softmax'))\n",
    "        opt = optimizers.Adam(lr=lr)\n",
    "        hist = model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "        print(model.summary()) \n",
    "        hist = model.fit(Xtr_pca, y_train, batch_size=batch_size,\n",
    "              epochs=nepochs, validation_data=(Xts_pca, y_test),\n",
    "              shuffle=False, verbose=0)\n",
    "        hist_value[0,i,j,:] = hist.history['loss']\n",
    "        hist_value[1,i,j,:] = hist.history['val_loss']\n",
    "        hist_value[2,i,j,:] = hist.history['acc']\n",
    "        hist_value[3,i,j,:] = hist.history['val_acc']\n",
    "# Determine the npc and nnode that provides the highest validation accuracy \n",
    "tmp = np.mean(hist_value[3,:,:,-10:],axis=2)\n",
    "tmp = np.argmax(tmp)\n",
    "n1 = tmp//len(npcs)\n",
    "n2 = tmp%len(npcs)\n",
    "opt_node = nnodes[n1]\n",
    "opt_npc = npcs[n2]\n",
    "print('Optimal nnode = ', opt_node)\n",
    "print('Optimal npc = ', opt_npc)\n",
    "# plt.contourf ...\n",
    "tmp = np.mean(hist_value[3,:,:,-10:],axis=2)\n",
    "NN, NP = np.meshgrid(npcs, nnodes)\n",
    "plt.figure()\n",
    "# tmp = np.reshape(hist_value[3,:,:,:],(4*5,nepochs))\n",
    "plt.contourf(NN, NP, tmp)\n",
    "plt.xlabel('Number of Nodes')\n",
    "plt.ylabel('Number of PCs')\n",
    "plt.grid()\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 46, 33, 8)         208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 23, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 19, 12, 8)         1608      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 6, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 432)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               86600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 89,421\n",
      "Trainable params: 89,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data preparation for input to CNN\n",
    "Xtr = np.reshape(X_train.astype('float32') / 255., (X_train.shape[0],h,w,1))\n",
    "Xts = np.reshape(X_test.astype('float32') / 255., (X_test.shape[0],h,w,1))\n",
    "# NN\n",
    "K.clear_session()\n",
    "model = create_mod(Xtr.shape[1:], n_classes, 8)\n",
    "model.summary()\n",
    "opt = optimizers.Adam(lr=lr)\n",
    "hist = model.compile(loss='sparse_categorical_crossentropy',\n",
    "          optimizer=opt,\n",
    "          metrics=['accuracy'])\n",
    "# Fit the model using batch size=100, epochs = 40\n",
    "# Print the accuracy on the validation set\n",
    "\n",
    "# TO DO \n",
    "batch_size = 100\n",
    "# nepochs = 4\n",
    "hist = model.fit(Xtr, y_train, batch_size=batch_size,\n",
    "      epochs=nepochs, validation_data=(Xts, y_test),\n",
    "      shuffle=False, verbose=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(nepochs), hist.history['val_acc'], label='CNN')\n",
    "plt.plot(np.arange(nepochs), hist_value[3,n1,n2,:], label='PCA+NN')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How does CNN compare with PCA+NN with the small training set? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
